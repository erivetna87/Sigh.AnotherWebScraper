Title,Location,Company,Salary,Sponsored,Description
Data Scientist,"Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.

Austin Base Salary Range: 106,000 - 128,000 USD per year

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
Requirements

BS in Computer Science, Statistics, Mathematics or a closely related quantitative field
2 years of professional industry experience in Data Science, Business Analytics, or Data Analysis
Expertise in machine learning and statistical modeling
Passion to answer Product/Engineering questions with data
Strong ability to code in Python
We get excited about candidates who:
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring of data science products
Are proficient in small data modeling work: Python, R, Julia, Octave
Are proficient in big data modeling work: Hadoop, Pig, Scala, Spark
Can fish for data: SQL, Pandas, MongoDB
Deploy data science solutions: Java, Python, C++
Communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
"Sr. Manager, Data Science","Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
You understand that the best managers serve their teams by removing roadblocks and giving individual contributors autonomy and ownership. You have high standards and will take pride in Indeed and push teammates to be better. You have delivered challenging technical solutions at scale. You have led Data Science or Engineering teams, and earned the respect of talented practitioners. You are equally happy talking about deep learning and statistical inference, as you are brainstorming about practical experimental design and technology career development. You love being in the mix technically while providing leadership to your teams.

Requirements
Significant prior success as a Data, Product, or Decision Scientist working on challenging problems at scale
Master’s or PhD., with advanced coursework in statistics, machine learning, programming, or related skills
5+ years of industry experience, with expertise in statistical modeling and/ or machine learning
The ability to guide a team to achieve important goals together
Expertise in machine learning and statistical modeling
Strong ability to code in Python
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring
Strong desire to solve tough problems with scientific rigor at scale
An understanding of the value derived from getting results early and iterating
Ability to write and present results to both technical and non-technical audiences
Strong ability to coach Data Scientists, helping them improve their skills and grow their careers
Passion to answer Product/Engineering questions with data
We get excited about candidates who can:
Program using R, Python, Java, or C++
Perform big data modeling work: Hadoop, Pig, Scala, Spark
Fish for data: SQL, Pandas, MongoDB
Deploy Data Science solutions: Java, Python, C++
Can communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Fixed Income Quantitative Analyst / Data Engineer,"Austin, TX 78702 (East Cesar Chavez area)",Simplex,,Organic,"Our client is a well regarded, highly successful real estate (Fixed Income / Mortgage Backed Securities) investment and technology firm headquartered in Austin, TX. They are looking for a MBS / Fixed Income Quantitative Analyst / Data Engineer reporting directly to the CTO to join an established team of Data Engineers with experience in the Fixed Income / Mortgage Backed Securities (MBS) space. You will sit on the Data Engineering team however since you will be collaborating closely with modeling, any experience with modeling would be a big plus.
We are looking for a Quantitative Analyst / Data Engineer who is self-motivated, intellectual curiosity to understand the complexities of financial markets and has experience with fixed income / mortgage backed securities. The individual will have opportunities to be part of high-level meetings with senior members of the investment teams and have a direct impact on the company's strategy and success. While you will be working primarily on the Fixed Income business, our client has multiple business lines with unlimited opportunity to contribute across a wide range of programs / platforms.
Responsibilities:
Curate MBS Data used in different models and lead efforts to leverage data better / faster. Investigate new sources of data to improve current models.
Be the bridge between the various teams like modeling, strategy, and research with the goal of generating data driven insights to enhance investment outcomes for the MBS desk. You will be tailoring communication of complex concepts to a variety of audiences.
Drive and use relational-based database technologies and Big Data platforms to research innovative techniques to solve problems in support of fixed income investment decisions.
Develop business acumen to bring an informed perspective to investment management teams.
Requirements:
Heavy SQL experience as well as exposure to related technologies like Microsoft SQL Server, Oracle, MySQL, Hive, Presto, etc.
Data Engineer experience in the Fixed Income / Mortgage Backed Securities space.
MBS Financial Modeling / Intex modeling / data experience is a big plus (But this is not a financial modeling role).
Experience with languages such as Python, C#, C++, C, R, and Big Data related technologies.
Open to re-location to Austin, TX and we will assist with re-location."
Senior Data Scientist - Work from Home!,"Austin, TX 73301 (St Edwards area)",Jobot,,Organic,"This Jobot Job is hosted by: Drew J. Fibus
Are you a fit? Easy Apply now by clicking the ""Apply On Company Site"" button and sending us your resume.
Salary: $125,000 - $175,000 per year

A bit about us:
** Work from Home!** We are a fast-growing startup that is revolutionizing the water conservation/IoT tech space! We are the 1st in the Industry to integrate Water, Internet of Things (IoT), Full Stack Cloud Platform, AI/ML, Predictive Analytics and Data Science with a comprehensive patented solution of hardware devices (sensor nodes), secure IoT connectivity and an intelligent SaaS software platform for customer analytics while maintaining the reliability and data accuracy demanded in the Industry. We are very close to securing our Series A and are actively looking for a Senior Data Scientist to lead our team!

If you are a Senior Data Scientist with 5+ years experience then please apply today!

What can we do for you?
Do you want to help save the worlds most precious resource? We do too!

Competitive Base Salary!

Extremely Competitive Equity Package!

Flexible Work Schedules!

Accelerated Career Growth!
Is your background a fit? We are looking for…

Master's or PhD in Computer Science or similar plus:
Strong understanding of machine
learning algorithms & principles (regression analysis, time series,
probabilistic models, supervised classification and unsupervised
learning), and their application.
Expert in data
mining, machine learning, deep learning, statistical modeling and data
visualization techniques using data-oriented tools and languages such
Python or R with data analysis libraries (pandas, sklearn, numpy, scipy,
dash and matplotlib)
5+ years
experience writing SQL-like as well as NoSql queries and databases
3+ years
hands-on industry work experience designing and building large-scale data,
machine learning, and analytics applications and pipelines that are
well-designed, cleanly coded, well-documented, operationally stable, and
timely delivered
Applied Machine
Learning experience (regression analysis, time series, probabilistic
models, supervised classification and
unsupervised learning).
Strong
mathematical background (linear algebra, calculus, probability and
statistics).
Experience with
scalable ML (MapReduce, streaming).
Experience with
deep learning algorithms and techniques, including but not limited to: CNN,
LSTM, RNN, TensorFlow, Keras, Caffe, PyTorch
Experience
setting up and using large-scale distributed data-processing frameworks
such as Apache Spark and Hadoop Map-Reduce
Experience
working with enterprise-grade cloud computing platforms such as AWS, Azure
or GCP
Why join us?
We can offer you the opportunity to work on State-of-the-Art technology and make a meaningful and important impact on today’s society and the next generation! Help us revolutionize the water conservation industry and enjoy accelerated career growth with exciting equity stake in the world’s 1st and only patented water/IoT/Cloud technology!"
"Software Engineer, Machine Learning","Austin, TX 78716",SailPoint Technologies,,Organic,"At SailPoint, we do things differently. We understand that a fun-loving work environment can be highly motivating and productive. When smart people work on intriguing problems, and they enjoy coming to work each day, they accomplish great things together. With that philosophy, we’ve assembled the best identity team in the world that is passionate about the power of identity.

As the fastest-growing, independent identity and access management (IAM) provider, SailPoint helps hundreds of global organizations securely and effectively deliver and manage user access from any device to data and applications residing in the data center, on mobile devices, and in the cloud. The company’s innovative product portfolio offers customers an integrated set of core services including identity governance, provisioning, and access management delivered on-premises or from the cloud (IAM-as-a-service).

SailPoint is seeking a Sr/Staff Data Software Engineer to help build a new cloud-based identity analytics product incorporating real-time data pipelines, machine learning algorithms and multi-tenancy support. We are looking for well-rounded backend or full stack engineers who are passionate about building and delivering reliable, scalable microservices and infrastructure for SaaS products.

Responsibilities
Collaborate with peers on requirements, designs, code reviews, and testing
Produce designs and rough estimates, and implement features based on product requirements
Deliver efficient, maintainable, robust Java/Scala based microservices
Produce unit and end-to-end tests to improve code quality and maximize code coverage for new and existing features
Productize and operationalize machine learning algorithms
Actively engage in technology discovery that can be applied to the product
Requirements
7-10 years of professional software development experience
2+ years of data engineering or related experience
Strong Java and/or Scala experience
Experience with Agile development practices and continuous delivery
Proficient understanding of distributed computing principles. microservice architectures and patterns
Experience with integration of data from multiple data sources
Experience writing unit and integration tests
Great communication skills
BS in Computer Science or a related experience
Preferred
Experience with Cloud computing architectures (AWS, Google Cloud)
Experience with Kafka, Flink/Spark, Elasticsearch technologies or related
Experience integrating data pipelines for machine learning
Experience with container technologies (Docker, Kubernetes, etc.)
Experience with NoSQL databases, such as Redshift, Cassandra, DynamoDB
Experience instrumenting code for gathering production performance metrics
Compensation and benefits
Experience a Small-company Atmosphere with Big-company Benefits
Competitive pay, 401(k) and comprehensive medical, dental and vision plans
Recharge your batteries with a flexible vacation policy and paid holidays
Grow with us with both technical and career growth opportunities
Enjoy a healthy work-life balance with flexible hours, family-friendly company events and charitable work
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status.
k
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status."
"Data Scientist - Sports Analytics (Full-Time, Entry-Level, S...","Austin, TX 78703 (Old West Austin area)",Zelus Analytics,,Organic,"We are seeking entry-level data scientists with a passion for sports to develop the quantitative models that power our world-leading sports intelligence platform. The projected start date would be the summer of 2020.
Zelus Analytics combines a fast-growing startup environment with a research-focused culture. We pride ourselves on offering our employees the freedom and mentorship to develop and expand their analytical skills. Our goal is to help the professional teams in our exclusive partner network compete and win championships. In so doing, we hope to create a new path for highly talented data scientists to push the cutting edge of sports analytics.
Job Functions:
Statistical modeling and quantitative analysis to support one or more research projects focused on player evaluation and in-game strategy
Developing, validating, and automating quantitative models using statistics, machine learning, optimization, and simulation
Attending sports analytics conferences and reviewing public research
Preparing reports and presentations to share model specifications and validation results
Performing ad hoc data analysis to support our partner teams
Other duties and responsibilities as assigned
Requirements:
B.S., M.S., or Ph.D. in applied mathematics, statistics, computer science, operations research, or a related quantitative field
Industry or research experience with applied mathematical and predictive modeling (statistics, machine learning, optimization, and/or simulation)
Experience working with sports data, through academic research, independent projects, and/or prior internships
Fluency with mathematical and statistical programming (Python and/or R)
Familiarity with relational databases and cloud-based computing
Desire to work in a collaborative team environment
Enthusiasm for sports analytics and knowledge of recent public advances in the sports analytics research community
You should definitely apply if:
You are passionate about sports analytics and relish the opportunity to explore complex, private data sets on behalf of professional sports teams
You would enjoy the exciting pace and upside of working for a tech startup in one of the best places to live in the U.S.
In addition to competitive salaries, our compensation packages include equity and benefits, such as a 401(k) plan and unlimited PTO, that allow us to compete with professional sports teams for the best available talent. Zelus Analytics is committed to creating a diverse and inclusive work environment where all of our employees can thrive.
Job Type: Full-time
Salary: $70,000.00 to $100,000.00 /year
Experience:
Predictive Modeling: 1 year (Preferred)
R: 1 year (Preferred)
Python: 1 year (Preferred)
Education:
Bachelor's (Required)
Location:
Austin, TX 78703 (Required)
Work authorization:
United States (Required)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Flexible schedule
Parental leave
Relocation assistance
This Job Is Ideal for Someone Who Is:
Achievement-oriented -- enjoys taking on challenges, even if they might fail
Autonomous/Independent -- enjoys working with little direction
Innovative -- prefers working in unconventional ways or on tasks that require creativity"
Data Science Analyst,"Austin, TX 78746",Revionics,,Organic,"Role and Responsibilities:
Revionics has an immediate opening in our Austin HQ in the Science Services team for a Data Science Analyst. This individual will work in a fast-paced environment as part of multi-disciplinary project teams to deliver analytic services to retailers. The successful candidate will bring a balance of creative problem solving, hands-on data skills and practical analytic skills to the organization. Strong communication skills and experience in a related analytics role are desired. This position may require up to 20-30% travel, mostly to sites across the USA/to EU sites.

What you’ll do:
Develop a solid understanding of Revionics’ core set of science services and of the science behind Revionics’ solutions,
Execute and deliver analytical services for customers. Examples include Data Validation, Pricing Strategy Analysis, Key Value Item identification, Basket Analysis, Store Clustering and Promotion Performance Analysis,
Assist in analyzing results from Revionics’ demand models and forecasts using hindcast holdout sample and modeling tuning techniques,
Assist in Value Measurement analysis to demonstrate the value of our price optimization solution for existing customers,
Work with Price Strategy Consultants, Project Managers, Systems Engineers, and Client Partners in the delivery of data science services and sharing of analytical insight as part of client projects,
Collaborate with other members of the science teams to help improve automation & efficiency of existing science services and analytic workflow scripts using a combination of Python, SQL, Google Cloud Platform tools and in-house software tools
What you have:
Masters (preferred) in Operations Research, Econometrics, Data Science, Mathematics, Physical Sciences or equivalent,
Strong quantitative, mathematical and analytic skills and ability to understand use of statistical solutions to business problems,
Strong problem-solving skills and ability to interpret analytic results and diagnose issues using structured, data-driven methods
Strong data skills including experience with outlier identification and data cleansing
SQL and relational databases skills (MS SQL Server, Oracle, etc.),
Experience with analytic scripting languages applications (Python highly desired, R, MatLab, Alteryx etc),
Data visualization skills (Tableau highly desired) and ability to present complex information to technical and non-technical audiences,
Strong communication and presentation skills
How you can stand out:
Proficiency with Python, JuPyter notebooks, SciPy, numPy
Familiarity applying analytics in industry (Retail, financial, credit, etc.)
Strong proficiency with visualization tools and business intelligence applications (Tableau, Alteryx, etc.)
Familiarity with statistical regression and modeling techniques (least squares, maximum likelihood, Bayesian estimation.)
Familiarity with Classification and Clustering methods (K-means, Non-hierarchical, etc.)
Software development languages tools (C++, C#, Java)
Familiarity with data load and ETL / Automation tools (Informatica, etc.)
Fluency in German, Russian, Spanish or other European languages
Who We Are:
Predictive. Prescriptive. Profitable Retailing.

We provide SaaS-based pricing, promotion, markdown and space solutions. Retailers in all segments across the world adopt our self-funding model to improve top-line sales, demand, and margin. Our customers gain that competitive edge and improve their value proposition while outmaneuvering competitor price aggressiveness.

During the days of first-generation price optimization solutions, at a time where science in retail was viewed as voodoo, our founder Jeff Smith nurtured the concept that there could be a better way. He went on to form Revionics around that new-generation vision, and to this day we remain committed to his goal: To help retail businesses and everyday users solve complex pricing challenges leveraging the latest machine learning science with a completely transparent process, usable in an intuitive way that fits into retailers’ normal business flows.

Our company success is based on our 4 foundational pillars:
A SaaS-based architecture for fast ROI
Productized, transparent science
Machine Learning algorithms that continue to evolve with changing market conditions and shopper behaviors for built-in future proofing
A supportive culture focusing on both our people and customers’ well-being.
Our Core Values:
Integrity: Be honest, dependable and complete
Transparency: Anticipate questions and give clear, usable answers.
Continuous Improvement: Be relentless about improvement – for ourselves and our customers
Curiosity: Shine lights in dark corners; seek to ensure we know what we don’t know
Accountability: Own the problem and the solution
Dedication: Don’t stop until the numbers are right and systems are up
Humility: Put the spotlight on our customers, not ourselves"
Entry-Level Data Science and AI Curriculum Developer,"Austin, TX 73344",IBM,,Organic,"Introduction
The Data and AI Learning organization is building programs through which we will share IBM’s wealth of resources in fields such as artificial intelligence, cloud computing, security and quantum computing to name a few. These program will be shared with organizations around the world, and we are seeking candidates with a real passion for skills development. Join us to help IBM significantly impact the growth of these skills in the market, and to deepen your own technology skills.

Your Role and Responsibilities
What You'll Do
Will be responsible for building/updating client-facing learning offerings focused on Data Science and AI best practices and technologies working with curriculum leads, and other IBM subject matter experts.
Develop training content in key offering modalities (instructor-led training, self-paced learning, online learning)
Create effective training that will bring value to our clients through a positive learning experience with IBM.
Develop learning assets that will be used to showcase our technology leadership and to teach clients to learn how to leverage their IBM technology.
Work with curriculum leads in the AI Learning and Certification team, to develop courses, plans, timelines, and success metrics
Who you are:
You have a passion for working collaboratively across IBM and IBM’s ecosystem to build successful programs
You have very strong written, verbal, and interpersonal communication skills
You have the ability to quickly grow expertise in IBM technology areas which are relevant to the business

Required Technical and Professional Expertise
Demonstrated work experience in an education-related field, training, program/project management
Proven track record of driving project timelines to meet program objectives

Preferred Technical and Professional Expertise
Having knowledge of or experience with some IBM's specific technology offerings in areas such as Data Science, AI, as well as Open Source products such as Python.
Basic knowledge with Adobe Captivate, Camtasia and/or Adapt
Proven work experience in an education-related field in Data Science, Machine Learning and AI
Instructional Design knowledge
Masters of Science degree in Analytics, Data Science, or related field

About Business Unit
No matter where you work in IBM, you are making an impact. As an Early Professional with IBM, you will be taking on a key role with one of our industry-leading business units to work on the technology that is solving our most challenging problems and changing the way the world thinks.

Your Life @ IBM
What matters to you when you’re looking for your next career challenge?

Maybe you want to get involved in work that really changes the world? What about somewhere with incredible and diverse career and development opportunities – where you can truly discover your passion? Are you looking for a culture of openness, collaboration and trust – where everyone has a voice? What about all of these? If so, then IBM could be your next career challenge. Join us, not to do something better, but to attempt things you never thought possible.

Impact. Inclusion. Infinite Experiences. Do your best work ever.

About IBM
IBM’s greatest invention is the IBMer. We believe that progress is made through progressive thinking, progressive leadership, progressive policy and progressive action. IBMers believe that the application of intelligence, reason and science can improve business, society and the human condition. Restlessly reinventing since 1911, we are the largest technology and consulting employer in the world, with more than 380,000 IBMers serving clients in 170 countries.

Location Statement
For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM
IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
Data Engineer,"Austin, TX",Apple,,Organic,"Summary
Posted: Jan 27, 2020
Weekly Hours: 40
Role Number:200144357
At Apple, excellent ideas have a way of becoming extraordinary products, services, and customer experiences very quickly. Bring passion and dedication to your job and there's no telling what you could accomplish. Would you like to work in a fast-paced environment where your technical abilities will be challenged on a day-to-day basis? If so, Apple's Global Business Intelligence (GBI) team is seeking a hardworking Data Engineer to build high quality, scalable and resilient distributed systems that power apple's analytics platform and data pipelines. Apple's Enterprise Data warehouse system cater to a wide variety of real-time, near real-time and batch analytical solutions. These solutions are integral part of business functions like Sales, Operations, Finance, AppleCare, Marketing and Internet services enabling business drivers to make critical decisions. We use a diverse technology stack such as Teradata, HANA, Vertica, Hadoop, Kafka, Spark, and Cassandra and beyond. Designing, Developing and scaling these Big Data technologies are a core part of our daily job. The team member will be able think outside of the box and should have passion for building analytics solutions to enable business in making time sensitive and critical decisions.
Key Qualifications
We would like for you to have In-depth understanding of data structures and algorithms
We are looking for experience in designing and building dimensional data models to improve accessibility, efficiency, and quality of data
Database development experience with Relational or MPP/distributed systems such as Oracle/Teradata/Vertica/Hadoop
We are seeking programming experience in building high quality software in Java, Python or Scala preferred
Experience in designing and developing ETL data pipelines. Should be proficient in writing Advanced SQLs, Expertise in performance tuning of SQLs
You will demonstrate excellent understanding of development processes and agile methodologies
Strong analytical and interpersonal skills
Enthusiastic, highly motivated and ability to learn quick
Experience with or advance courses on data science and machine learning is ideal
Work/project experience with Big Data and advanced programming languages is a plus
Experience developing Big Data/Hadoop applications using java, Spark, Hive, Oozie, Kafka, and Map Reduce is a huge plus
Description
You will build and design data structures on MPP platform like Teradata, Hadoop to provide efficient reporting and analytics capability. Design and build highly scalable data pipelines using new generation tools and technologies like Spark, Kafka to induct data from various systems. Translate complex business requirements into scalable technical solutions meeting data warehousing design standards. Strong understanding of analytics needs and proactive-ness to build generic solutions to improve the efficiency. Build dashboards using Self-Service tools like Tableau and perform data analysis to support business. Collaborate with multiple multi-functional teams and work on solutions which has larger impact on Apple business. We seek a self starter, forward-thinking person with strong leadership capabilities. Ability to communicate effectively, both written and verbal, with technical and non-technical multi-functional teams. You will interact with many other group’s internal team to lead and deliver elite products in an exciting rapidly changing environment.
Education & Experience
Bachelors Degree"
Data Science,"Austin, TX 78738",TransVoyant,,Organic,"TransVoyant is looking for a Data Science Intern to assist with live and predictive analytics research, design and development for our patented Continuous Decision Intelligence™ Platform. In this role, you will structure data and create the analytics needed to provide insights into our customer domains–ranging from predicting customer demand to forecasting port disruptions to getting in front of risks to national security. This position will craft statistical models, test hypotheses and visually summarize, interpret and report on TransVoyant CDI™-driven intelligence.

RESPONSIBILITIES
Become an expert on TransVoyant CDI™ Platform solutions and how they solve pressing customer challenges within National Security and Business Intelligence arenas
Identify, retrieve, manipulate, relate and exploit multiple TransVoyant structured and unstructured data sets from thousands of various sources (ex. tweets, live aircraft, forecast weather), including building or generating new data sets as appropriate
Create methods, models and algorithms to understand the meaning of streaming live data, translating it into insightful predictive output for customer applications and data products
Educate internal staff (ex. development, sales, marketing) on how data science and resulting predictions can be productized for key industry verticals
Assist with pre-sales and post-sales engagements–performing hands-on customer work when required
Keep up to date on competitive solutions, products and services

DESIRED SKILLS & EXPERIENCE
Cloud-based data analysis, manipulation and visualization experience
Understanding of Hadoop stack and data analytics tools to exploit massive sets of TransVoyant data (e.g. HDFS, Spark, R, SQL, etc.)
Ability to explain technical and statistical findings to non-technical users and decision makers
Honed presentation and product demo skills
Experience in technical consulting and conceptual solution design
Basic programming and scripting experience with Java, JavaScript, and JSON is not mandatory, but is considered a plus
Domain knowledge in enterprise demand, supply chain, and/or transportation management and visibility technologies is a plus
Domain knowledge in national security anticipatory intelligence and situational awareness is a plus
Must be a U.S. Citizen
ABOUT TRANSVOYANT
TransVoyant delivers our customers continuous insights to increase revenues, reduce costs and manage risks by combining the current and future behavior of their enterprises, their ecosystems and they dynamic world around them. We are innovative, creative, focused on customer success and love what we do. Team members enjoy highly competitive compensation, a fast-growing and flexible work environment, comprehensive benefits, 100% 401k matches, unlimited vacation days and professional development opportunities.

We respect your personal information. Please review our Privacy Policy to find out more.
QuE50PdlKc"
Clinical Data Scientist,"Austin, TX",Babson Diagnostics,,Organic,"Clinical Data Scientist
Babson Diagnostics is searching the Austin area for a full-time Clinical Data Scientist. The role reports to the Head of Research & Development. This salaried position is Monday-Friday and does not involve any on-call, weekends, or major holidays. The full compensation package includes complete medical, dental, and vision insurance coverage as well as paid time off.
Babson Diagnostics is a medical technology company with a new vision for diagnostic blood testing. Our proprietary technology is designed to produce accurate diagnostic results from small capillary samples collected at convenient retail locations and analyzed at our CLIA-certified clinical laboratory. With scientific integrity, humility, and kindness, we are working to improve our customers’ health by making diagnostic blood testing more convenient, accessible, and human.
We are a Science-first company and are founded on the principle that scientific rigor can never be compromised. Prior to commercialization, we are working with local and national retail pharmacies to validate our technology by conducting clinical studies intended for peer-reviewed publication.
The Clinical Data Scientist role is responsible for:
Data and database management for clinical studies.
Validating data accuracy and completeness.
Analyzing data using statistical techniques and technical assessments.
Creating statistical analysis plans and procedures.
Communicating statistical results and writing analysis sections for protocols and manuscripts.
Supporting a wide variety of projects in laboratory development, laboratory testing, and medical device development.
Assisting with daily laboratory operations.
Assisting assay feasibility and optimization experiments on automated analyzers.
Executing reliability studies and determining failure modes for medical devices and workflows.
Assisting with assay troubleshooting and root cause analyses.
Assisting with verification and validation of assays according to defined protocols.
Creating reports, charts, graphs, and documentation to support multiple projects.
Candidates for the role must have the following qualifications:
Degree in a related field with a GPA of 3.0 or higher.
Experience with database architecture, clinical studies, and clinical data management.
Experience with complex statistics and biostats.
Strong programming skills (particularly R, Python, SPSS, and/or SAS).
Authorship or co-authorship of publications in relevant journals.
Strong written and oral communication skills.
Exceptional attention to detail and commitment to quality.
Project ownership and the ability to work independently.
Willingness to work with human specimens (e.g. blood).
Willingness to learn and develop new skills over time.
Ability to prioritize, multitask, and meet deadlines.
Flexibility and creativity compatible with a rapidly-changing startup environment.
Our ideal candidate would also have:
Advanced degree in a related field with a GPA of 3.5 or higher.
Experience with common wet laboratory procedures such as pipetting and weighing.
Experience with medical device development and optimization.
Experience with specimen collection device development.
Experience with assay development, clinical chemistry, and/or reliability engineering.
Experience with MiniTab, SAS, SPSS, or similar statistical software.
Physically, the day-to-day functions of the role require:
Standing and/or sitting for extended periods of time.
Occasionally lifting and carrying items weighing up to 40 lbs.
A normal range of vision and hearing (inclusive of candidates using corrective measures such as glasses or hearing aids).
Occasional repetitive motions.
Babson Diagnostics embraces diversity and inclusion and ensures that all qualified applicants are considered for employment without regard to age (other than minimum age of 18), race, ethnicity, national origin, color, religion, political ideology, sex, pregnancy, sexual orientation, gender identity, disability, or veteran status. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential job functions.
Job Type: Full-time
Experience:
programming: 3 years (Required)
clinical data management: 3 years (Required)
biostatistics: 3 years (Required)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Paid time off"
Associate Data Scientist,"Austin, TX 78701 (Downtown area)",Levelset,,Organic,"Each month over 500,000 contractors and suppliers connect on Levelset's cloud-based platform to make payment processes stress-free. Users easily exchange payment documents like lien waivers, pay applications, and preliminary notices, they see a complete picture of who is on their job, and are empowered with the resources and knowledge they need to be confident in payment. The results are faster payments and fewer surprises.
All of this activity generates millions of entities, records, attribution, and entity relationships. We use this data to create insights about the payment activity of projects and contractors, which helps our users get paid. That's where you come in.
You'll be Levelset's first Data Scientist and have the opportunity to influence how we expand our data science use cases across the business and products. You will need to be a ""data utility player"" and be prepared to be able to move data around, analyze opportunities, select the tools and build the infrastructure to support data science, and use our data to innovate our product and advance our purpose. The work you do and models you build will have a direct impact on our users.
Types of projects you'll be working on:

Text Analysis and Entity Recognition
We send thousands of documents and ingest thousands more from external sources. This data is messy, sometimes unstructured, and we need to be smarter about how we correlate company entities. How can we tell if two companies with similar names are the same or different?
We are collecting thousands of reviews from our users to capture feedback on different contractors on things like payment timeliness, communication practices, etc… How can we summarize the overall sentiment of reviews for a specific contractor and what are the common pros / cons?
Advanced Analytics and Data Discovery
We have a lot of data on the payment history of contractors. How can we rate the payment risk of a contractor and share that information with users in a helpful, digestible way?
A large commercial construction project can last many years and include hundreds of contractors. Or a single address can have multiple projects over the years with different contractors. Or a property, like an office building, can have different distinct projects going on at one time. How can we tell the difference?
Data Modeling and Heuristics
A user is on a project that we know other subcontractors are experiencing slow payment on. What other documents should we recommend the user do to ensure they get paid?
Most of the construction industry is based on working relationships and prior work history. What relationships and other parties can we infer that are working on the project based on the existing connections from other projects we see in our graph?
Skills you'll need:
1-3 years of experience working with Machine Learning, Optimization, Neural Networks and/or Artificial Intelligence
A broad understanding of data science techniques and a willingness to ""go deep"" and learn more about a specific topic as it relates to our opportunities.
Data cleansing experience using various utilities and programming techniques
Text analytics, natural language processing, and entity recognition/extraction to turn documents into information
Data processing / ETL to prep and clean data for analysis and production pipelines.
R / Python / SQL / Cypher.
You'll be helping us build our DS stack out, but familiarity with the tools we have in place will help, including: MySQL, Redshift/Postgres, Neo4j, Kafka, RabbitMQ, and the AWS stack.

Why Levelset?
Levelset is one of the South's fastest-growing tech companies with 100% growth year over year. Named New Orleans City Business ""Best Place to Work,"" ""Top Company Culture"" by Entrepreneur Magazine, part of the Inc. 5,000 fastest growing companies, and voted best company for leadership, perks and benefits, work-life balance, and professional development as well as best CEO for woman and diversity by Comparably.
We push ourselves to break records and to drive the growth of the company while we celebrate wins and have fun every day. We will invest in you, we will challenge you, and we will push you to grow. You will be surrounded by the best colleagues and given the opportunity to shake up a billion dollar industry.
We care where you will be in 3 years, 5 years, and 10 years and we're invested to help you get there.
You're joining a stellar team where you can have a huge impact and help us change the world.
We have a very competitive health benefits package and a fun office environment.
We have monthly company parties and catered lunch every Wednesday.
We offer unlimited vacation and an annual personal travel stipend.
xdPEX5WT3e"
Data Scientist,"Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.

Austin Base Salary Range: 106,000 - 128,000 USD per year

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
Requirements

BS in Computer Science, Statistics, Mathematics or a closely related quantitative field
2 years of professional industry experience in Data Science, Business Analytics, or Data Analysis
Expertise in machine learning and statistical modeling
Passion to answer Product/Engineering questions with data
Strong ability to code in Python
We get excited about candidates who:
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring of data science products
Are proficient in small data modeling work: Python, R, Julia, Octave
Are proficient in big data modeling work: Hadoop, Pig, Scala, Spark
Can fish for data: SQL, Pandas, MongoDB
Deploy data science solutions: Java, Python, C++
Communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Data Science Interns,"Austin, TX 78730",SailPoint,,Organic,"SailPoint is seeking Data Science Interns to join our team of, data scientists, engineers, and designers to deliver the next generation of Machine-Learning-powered solutions. At S ailPoint , you will work on the latest tools in Machine Learning, Big Data, Cloud Computing, Graph Databases to solve challenging problems. This is a paid internship that requires a highly motivated and results-driven personality who will thrive in a fast-paced environment. This is an excellent opportunity for an individual who wants to work as part of a skilled team to gain valuable experience in Data Science or Data Engineering developing actual products.

Qualifications:

Sophomore, Junior, or Senior of a four-year university with Data Science concentration , or postgraduate students in Math/Physics/Statistics/Data Science .

Availability to work full-time during the Summer or at least part-time during the Fall and Spring academic terms .

Expertise in R, Python .
Experience with data querying tools e.g. SQL, Hive.

Detail-oriented self-starter who can independently manage deadlines .

Positive attitude and team player .

Preferred Qualifications:

Expertise in Machine Learning algorithms and techniques .
Experience with PySpark, Scala.

Experience with High Performance computing , e.g. Python’s dask.
Experience with visualization and DS web app prototyping tools, e.g. Shiny, Plotly’s dash, flask.
Experience with Big Data tools.
All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status."
Data Scientist - Healthcare Exp Required,"Austin, TX 78704 (Zilker area)",ClosedLoop.ai,,Organic,"**ClosedLoop was recognized as one of BuiltInAustin's top startups to watch in 2019 and was recently awarded as a 50 on Fire winner from AustinInno!**
ClosedLoop’s data science platform combines leading-edge AI tools and automation capabilities with healthcare specific content and expertise enabling healthcare data scientists to build accurate and explainable predictive models with speed and ease. As an experienced Healthcare Data Scientist, you’ll actively contribute to the development of our state of the art automated machine learning platform. Your work will be deployed into customer environments in days, not months, and you’ll receive immediate feedback on what’s working and what isn’t.
**At this time, we are unable to sponsor employment for employees**
Responsibilities and Duties - Join ClosedLoop to
Work with comprehensive, real world medical data in all its messy glory
Apply cutting edge techniques in deep learning, natural language processing, and statistical analysis to real problems facing people and organizations delivering and paying for health care.
Dive deep into the understanding of healthcare data and work to present our results in a way our customers can easily understand and relate to.
Work as part of a team with engineers and domain experts to develop highly functional and beautiful products that integrate machine learning
Qualifications and Skills
Bachelors or higher in Computer Science or related technical field
2+ years working professionally as a healthcare specific data scientist
4+ years of engineering experience with Python
3+ years working experience in healthcare data science
Familiarity with relational databases
Understanding of machine learning and statistical analysis
Experience with:
Tensorflow
Pytorch
Scikit-learn
Numpy
Scipy
Seaborn
Matplotlib
Jupyter
Bayesian Methods
What employees are saying about ClosedLoop:
""Exciting place to work! - Company has great vision for the role of machine learning (and AI) in healthcare. Exciting to go to work every morning!""
""Work Hard and Feel Rewarded - The CEO and CTO have total faith in their team, and the employees ideas and opinions are highly respected and listen to. The passion for our company's mission is contagious from the executive team, which makes our high standards fair and rewarding.""
""Room to thrive""
Benefits
Competitive salary
Equity
Gear: Pick your tech
100% company covered for medical, dental, and vision for employees and their families
PTO
Other perks like Monday team lunches, fully stocked kitchen, and happy hours
Job Type: Full-time
Experience:
Data Science: 3 years (Preferred)
working with healthcare datasets: 2 years (Preferred)
Python: 3 years (Preferred)
Work authorization:
United States (Required)
Benefits:
Health insurance
Dental insurance
Vision insurance
Paid time off"
Data Science Engineer,"Austin, TX",Realtor.com,,Organic,"The Data Science Engineer will support our software developers, database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. The Date Science Engineer will consider optimizing or even re-designing our company‚Äôs data architecture to support our next generation of products and data initiatives. The Data Science Engineer should have the drive and ability to meet with relevant stakeholders, understand and model relevant data, and effectively communicate with an engineering team to put models into production. Demonstrating lifelong learning and collaboration; and willingness to take advice and fill gaps in knowledge is essential.
Duties & Responsibilities:
Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Engineering, Product and Data and teams to assist with data-related technical issues and support their data infrastructure needs.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
What We Like To See / Measures of Success:
M.S. or Ph.D. in Computer Science, or other quantitative field or a B.A./B.S. with 3+ years professional or research experience
Proficiency with SQL
Proficiency with Python
Expert in AWS technologies
End-to-end experience with data, including querying, aggregation, analysis, and visualization
Willingness to collaborate and communicate with others to solve a problem
Experience supporting and working with cross-functional teams in a dynamic environment
""Diversity is important to us, therefore, Opcity / Realtor.com is an Equal Opportunity Employer regardless of age, color, national origin, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, marital status, status as a disabled veteran and/or veteran of the Vietnam Era or any other characteristic protected by federal, state or local law. In addition, Opcity/ Realtor.com will provide reasonable accommodations for otherwise qualified disabled individuals. ""

Diversity is important to us, therefore, realtor.com is an Equal Opportunity Employer regardless of age, color, national origin, race, religion, creed, gender, sex, sexual orientation, gender identity and/or expression, marital status, status as a disabled veteran and/or veteran of the Vietnam Era or any other characteristic protected by federal, state or local law. In addition, realtor.com will provide reasonable accommodations for otherwise qualified disabled individuals."
Data Engineer,"Austin, TX",Seen by Indeed,,Organic,None
Machine Learning Ops Engineer,"Austin, TX 78702 (Govalle area)",Pensa Systems,,Organic,None
Data Engineer,"Austin, TX",Seen by Indeed,,Organic,None
Data Warehouse Engineer,"Austin, TX",Seen by Indeed,,Organic,None
Senior Data Engineer,"Austin, TX 78723 (St. Johns area)",Texas Mutual Insurance Company,,Organic,"Uses highly advanced technical skills and knowledge to develop complex data models, automated ETL processes, stored procedures, and views in MS SQL Server. Provides advanced technical expertise to staff, management, and end users, including in the area of new technologies and technical strategy. Works under minimal supervision.
Responsibilities & Qualifications
Responsibilities & Qualifications
You’re a fit if:
You want to have an important part of redesigning entire enterprise data platform and moving to cloud (AWS)
You have database experience including SQL, data modeling and performance tuning
You have experience managing and designing Data Lakes or other modern data structures
You have worked with AWS-based environments and solved data engineering problems in the cloud
You learn new technologies quickly and help others on the team become proficient
You enjoy working in an Agile environment and group setting to provide value to internal customers
You’re passionate about modern data design and getting data out of legacy data structures to make it more usable, efficient, and powerful
You care about data quality and implement techniques to ensure ongoing quality
You enjoy working directly with non-technical users to identify complex needs and translate into data solutions
Required qualifications:
At least 7 years of related data experience
Bachelor's degree in a related field
Experience developing modern data architectures
Experience building automated data pipelines using modern tools
Our Benefits:
Day one health, dental, and vision insurance
Performance bonus
401k plan with 4% basic employer contribution and 100% employer match contribution up to 6%
Vacation, sick, holiday and volunteer time off
Life and disability insurance
Flexible spending account
Free on-site gym and fitness classes
Professional development
Tuition reimbursement
Pet insurance
Free identity theft protection
Company-sponsored social and philanthropy events
Texas Mutual Insurance Company is an Equal Employment Opportunity employer."
Data Engineer,"Austin, TX","Aunt Bertha, a Public Benefit Corp.",,Organic,"Our Mission: To connect all people in need and the programs that serve them (with dignity and ease).
Aunt Bertha picks up where Uncle Sam leaves off by making it easy to find and apply for government and charitable social service programs. By organizing the world's human service program information, we make it easy for people in need and the people who help them to find help in seconds on www.auntbertha.com.
We are looking for people who are driven to make the world a drastically better place and want to join our small group of thoughtful, committed citizens because they believe, as Margaret Mead said, ""Never doubt that a small group of thoughtful, committed citizens can change the world; indeed, it's the only thing that ever has.""
Please note: If our mission doesn't strike a chord with you that is OK. But please consider not applying. We are seeking people who come on fire after learning about what we do.
What We Need Your Help Doing: The Data Engineer is essential to helping Aunt Bertha design, build and maintain a scalable data platform. This role is key in automating data processes to enable focusing on business value while eliminating toil; taking a lead role in schema design, indexing, data transformation, custom SQL development and other data-centric development tasks; working with engineering and infrastructure stakeholders to design and improve our database architecture; and working with our data architect to advocate for and introduce new technologies to solve data-related challenges and position us to make significant advances in new areas of data strategy.
Key Responsibilities:
Manage and optimize existing MySQL databases (schemas, indexing, security)
Design solutions to data-centric issues like performance, scalability and manageability
Use knowledge of various approaches to managing data (e.g. relational, document-based, columnar, etc.) to propose and design solutions that best fit the business needs
Write code for new system features, especially those related to data or reporting. There will be a heavy emphasis on implementing ETLs with proficiency in SQL and Python.
Work with the wider engineering team to validate and implement product-driven schema changes
Troubleshoot database issues and performance during development and testing, and create appropriate fixes
Follow established processes for documentation, testing and deployment of data-related features
Handle customer-reported data-related bugs and change requests
We are looking for someone who:
Is driven by the mission of helping others through building amazing software
Is competent with the languages and tools needed to develop database software
Keeps current with new data technologies and matches the right tool to the problem
Loves automating as much as possible
Communicates effectively in writing and speaking
Nice-to-have skills:
Experience with git
Familiarity with Pentaho or similar ETL tools
Experience in Google Cloud Platform or similar cloud-based infrastructure
Experience with Ansible or other infrastructure-as-code solutions
Apply Now! We are selecting from a broad field of candidates. If you are interested in learning more and think you have what it takes to win, please respond to this job posting with:
Your résumé
A short cover letter in which you tell us who you are, what you want to achieve in life and how this job will help you get there, and why Aunt Bertha should strongly consider a deeper conversation with you.
A cover letter is required! We get a lot of applicants, and only those who are truly engaged with our company mission will likely move forward. Additionally, please provide samples or links to any prior work that demonstrate your skill set, if available (e.g. a Github repo, portfolio page, etc.)
Physical Demands & Work Environment: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Some travel may be required.
We are proud to be an Equal Opportunity Employer and value diversity on our team.
Job Type: Full-time
Experience:
data/ETL: 3 years (Required)
Location:
Austin, TX (Required)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Parental leave
Other
Visa Sponsorship Potentially Available:
No: Not providing sponsorship for this job"
Product Scientist,"Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.

Austin Base Salary Range: 116,000 - 142,000 USD per year

Your job:
One of our core principles is a dedication to data-driven decision-making. To do that well, we need data scientists with a strong product sensibility to work alongside our product managers and technical leads.

Our Product Science team is a part of the Indeed Data Science group. While machine learning is one tool in our toolbox, Product Scientists use a variety of skills with the goal of driving business impact using whatever tools necessary.

Responsibilities
Help people get jobs!
Use quantitative analysis, data mining, and machine learning techniques to understand how hundreds of millions of jobseekers and employers are interacting on Indeed, and how those interactions are reflected in our data.
Work alongside product managers and engineering teams to help guide tactical and strategic product decisions.
Design and use statistically sound methodologies for evaluating hundreds of tests on thousands of web pages across dozens of business-relevant metrics.
Work alongside other data scientists and software engineers to expand Indeed's catalog of tools, techniques, and best practices for manipulating and interpreting terabytes of product data.
Share your work to a diverse audience across a variety of media. Help us promote and practice transparency by highlighting failures that we learn from as much as successes.
Work across a wide range of related areas- data extraction and cleansing, feature engineering, machine learning, exploratory analysis, data quality analysis, experimental analysis.
About you:
Requirements
MS in Computer Science, Statistics, Mathematics or a closely related quantitative field
3 years of professional industry experience in Data Science, Business Analytics, or Data Analysis * Experience coding in Python, R or another advanced data programming language
Strong communication and collaboration skills
Ability to write and present results to both technical and non-technical audiences
Driven to help their teammates and Indeed’s products
Experience designing and conducting complex projects
What we’d love to see (but isn’t required):
Master’s or PhD., with advanced coursework in statistics, machine learning, programming, or related skills
Relevant experience (including internships and/or research) in Business Analytics, Data Analysis, Product Management, Data Science, or related fields
In-depth knowledge and experience within consumer behavior, the consumer marketplace, and/or eCommerce fields
Experience building and/or pulling data using SQL
Production experience with machine learning and other advanced statistical methods
Deep understanding of designing and implementing A/B tests, and advanced extensions
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Fixed Income Quantitative Analyst / Data Engineer,"Austin, TX 78702 (East Cesar Chavez area)",Simplex,,Organic,"Our client is a well regarded, highly successful real estate (Fixed Income / Mortgage Backed Securities) investment and technology firm headquartered in Austin, TX. They are looking for a MBS / Fixed Income Quantitative Analyst / Data Engineer reporting directly to the CTO to join an established team of Data Engineers with experience in the Fixed Income / Mortgage Backed Securities (MBS) space. You will sit on the Data Engineering team however since you will be collaborating closely with modeling, any experience with modeling would be a big plus.
We are looking for a Quantitative Analyst / Data Engineer who is self-motivated, intellectual curiosity to understand the complexities of financial markets and has experience with fixed income / mortgage backed securities. The individual will have opportunities to be part of high-level meetings with senior members of the investment teams and have a direct impact on the company's strategy and success. While you will be working primarily on the Fixed Income business, our client has multiple business lines with unlimited opportunity to contribute across a wide range of programs / platforms.
Responsibilities:
Curate MBS Data used in different models and lead efforts to leverage data better / faster. Investigate new sources of data to improve current models.
Be the bridge between the various teams like modeling, strategy, and research with the goal of generating data driven insights to enhance investment outcomes for the MBS desk. You will be tailoring communication of complex concepts to a variety of audiences.
Drive and use relational-based database technologies and Big Data platforms to research innovative techniques to solve problems in support of fixed income investment decisions.
Develop business acumen to bring an informed perspective to investment management teams.
Requirements:
Heavy SQL experience as well as exposure to related technologies like Microsoft SQL Server, Oracle, MySQL, Hive, Presto, etc.
Data Engineer experience in the Fixed Income / Mortgage Backed Securities space.
MBS Financial Modeling / Intex modeling / data experience is a big plus (But this is not a financial modeling role).
Experience with languages such as Python, C#, C++, C, R, and Big Data related technologies.
Open to re-location to Austin, TX and we will assist with re-location."
Associate Data Scientist,"Austin, TX 78701 (Downtown area)",Levelset,,Organic,"Each month over 500,000 contractors and suppliers connect on Levelset's cloud-based platform to make payment processes stress-free. Users easily exchange payment documents like lien waivers, pay applications, and preliminary notices, they see a complete picture of who is on their job, and are empowered with the resources and knowledge they need to be confident in payment. The results are faster payments and fewer surprises.
All of this activity generates millions of entities, records, attribution, and entity relationships. We use this data to create insights about the payment activity of projects and contractors, which helps our users get paid. That's where you come in.
You'll be Levelset's first Data Scientist and have the opportunity to influence how we expand our data science use cases across the business and products. You will need to be a ""data utility player"" and be prepared to be able to move data around, analyze opportunities, select the tools and build the infrastructure to support data science, and use our data to innovate our product and advance our purpose. The work you do and models you build will have a direct impact on our users.
Types of projects you'll be working on:

Text Analysis and Entity Recognition
We send thousands of documents and ingest thousands more from external sources. This data is messy, sometimes unstructured, and we need to be smarter about how we correlate company entities. How can we tell if two companies with similar names are the same or different?
We are collecting thousands of reviews from our users to capture feedback on different contractors on things like payment timeliness, communication practices, etc… How can we summarize the overall sentiment of reviews for a specific contractor and what are the common pros / cons?
Advanced Analytics and Data Discovery
We have a lot of data on the payment history of contractors. How can we rate the payment risk of a contractor and share that information with users in a helpful, digestible way?
A large commercial construction project can last many years and include hundreds of contractors. Or a single address can have multiple projects over the years with different contractors. Or a property, like an office building, can have different distinct projects going on at one time. How can we tell the difference?
Data Modeling and Heuristics
A user is on a project that we know other subcontractors are experiencing slow payment on. What other documents should we recommend the user do to ensure they get paid?
Most of the construction industry is based on working relationships and prior work history. What relationships and other parties can we infer that are working on the project based on the existing connections from other projects we see in our graph?
Skills you'll need:
1-3 years of experience working with Machine Learning, Optimization, Neural Networks and/or Artificial Intelligence
A broad understanding of data science techniques and a willingness to ""go deep"" and learn more about a specific topic as it relates to our opportunities.
Data cleansing experience using various utilities and programming techniques
Text analytics, natural language processing, and entity recognition/extraction to turn documents into information
Data processing / ETL to prep and clean data for analysis and production pipelines.
R / Python / SQL / Cypher.
You'll be helping us build our DS stack out, but familiarity with the tools we have in place will help, including: MySQL, Redshift/Postgres, Neo4j, Kafka, RabbitMQ, and the AWS stack.

Why Levelset?
Levelset is one of the South's fastest-growing tech companies with 100% growth year over year. Named New Orleans City Business ""Best Place to Work,"" ""Top Company Culture"" by Entrepreneur Magazine, part of the Inc. 5,000 fastest growing companies, and voted best company for leadership, perks and benefits, work-life balance, and professional development as well as best CEO for woman and diversity by Comparably.
We push ourselves to break records and to drive the growth of the company while we celebrate wins and have fun every day. We will invest in you, we will challenge you, and we will push you to grow. You will be surrounded by the best colleagues and given the opportunity to shake up a billion dollar industry.
We care where you will be in 3 years, 5 years, and 10 years and we're invested to help you get there.
You're joining a stellar team where you can have a huge impact and help us change the world.
We have a very competitive health benefits package and a fun office environment.
We have monthly company parties and catered lunch every Wednesday.
We offer unlimited vacation and an annual personal travel stipend.
xdPEX5WT3e"
Data Analyst,"Austin, TX",SubjectWell,,Organic,"About SubjectWell
SubjectWell is a venture-backed startup on an unstoppable mission to disrupt the antiquated $100 billion dollar clinical trial patient recruitment sector. Almost all clinical trials fall behind schedule, leaving patients unable to access the most promising treatments and pharmaceutical and biotech companies unable to quickly carry their innovations to market. SubjectWell was founded by two entrepreneurs on their third successful startup, to unlock the potential of a true marketplace for clinical trials. We leverage proven data science and performance marketing techniques to hit a hard reset to the massive patient recruitment challenge that sits at the critical nexus of speeding delivery of the best therapeutics to the world.

Here's your chance to really make a difference, both in your career and in the lives of millions.


About the position
This position is for a Data Analyst whose role is to be an expert at understanding SubjectWell's data and to aid various teams in drawing insight. This includes creating dashboards, visualizations, algorithms, and business tools for use across the organization. If you are excited to work with data and to collaborate in figuring out how to rapidly drive improvements based on rich and diverse real-time data, this is a great opportunity to hone your skills.

Responsibilites and Duties
Work with business owners to identify reporting and analysis needs
Design and build the ETL processes for data to be used in reporting
Develop automated tools + dashboards to increase visibility of core KPIs
Facilitate delivery of ad hoc analysis and data requests
Ability to tell a story through data
Ensure data quality, consistency and security

Qualifications and Skills
Bachelor’s Degree in Math, Business, Economics, Computer Science or a related field
High levels of proficiency in SQL and query optimization for MySQL
Extensive experience with Tableau and Tableau Prep
Ability to exercise different problem-solving approaches to analyze data
Sufficient knowledge of probability and statistics to aid teams in understanding the strength of results
Fluent in at least one object-oriented programming language (e.g. Python, Java, Scala or R)

Benefits
Full Medical, Dental, and Vision Benefits
401(k)
Company stock options
Paid time off
Paid holidays
Casual office
Flexible vacation"
CRM and Data Engineer (Zoho One),"Austin, TX (South Lamar area)",Houndstooth Capital Real Estate,,Organic,"Houndstooth Capital Real Estate is a boutique real estate investment and development company in Austin, TX specializing in residential and multifamily assets. Houndstooth uses direct market intelligence to find real estate assets with value-add potential.
We are looking for a CRM expert to join our team. This is a high impact role, as our business relies on the efficient flow of information through our CRM. You will be responsible for the design, development, testing, and support of our customer relationship management ecosystem (Zoho One). You will lead and be responsible for designing and implementing our business processes to run on the Zoho One CRM platform.
This is a unique opportunity to collaborate with the founder and VP of Sales and dive into all parts of the process and learn the business by experiencing it first-hand. If you’re searching for a long-term partnership and a quick growth trajectory, this is the place for you.
As a Houndstooth team member, you bring a growth mindset, desire to learn new technologies/processes, strong communication skills and are a positive team player.
Every day will be different, but a majority of the time you will:
Own Zoho One’s full life cycle and it’s applications, including scripts, development roadmap, execution and maintenance
Drive strategic business results through building custom tools and scripts to automate manual business processes
Implement and customize business applications on Zoho One including CRM, Analytics, Motivator, Creator, Flow, Forms, Analytics, and other as needed
Migrate data from different systems into Zoho One from other platforms including third-party APIs such as the MLS
Create innovative, state-of-the-art applications and collaborate with the Sales team to gather requirements and develop software solutions
Develop and prioritize a feature development roadmap including new functionality, such as layouts, custom objects, and fields, reports and dashboards
Ensure HTML, CSS, and shared JavaScript is valid and consistent across applications
Utilize backend data services and contribute to increasing existing data services API
Optimize and improve the existing CRM system and work processes to scale efficiently
Document all components of the development process clearly
Keep abreast of new trends and best practices in web development
Produce efficient, clean, and well-commented code
Analyze, design, develop, test, and implement applications
Who you are:
Energetic self-starter, with a strong work ethic and sense of urgency who thrives in a fast-paced environment
Extreme owner over your work, solving problems proactively
Entrepreneurially spirited with a desire to work independently and drive your professional growth
Excellent communicator who values honesty and integrity
Well organized, detail-oriented with the capacity to multitask successfully
What you bring:
1 -2 years experience with a CRM product (Zoho CRM strongly preferred)
Ability to use one or more development language (PHP, Python, HTML, Java, MySQL, SQL Server, Linux, .NET, strong OOP concepts and/or C#)
Strong communication skills and a collaborative work style
Solutions-orientation with an eye for detail and identifying problems and roadblocks
Experience with IT troubleshooting principles and techniques
Understanding of and ability to implement application APIs
Bonus:
Experience with Zoho One including CRM, Analytics, Motivator, Creator, Flow, Forms, Analytics
Associates degree or higher in Computer Science, Information Systems, or Computer Engineering
Job Type: Full-time
Salary: $55,000.00 to $60,000.00 /year
Work Location:
One location
Benefits:
Paid time off
This Job Is:
A job for which military experienced candidates are encouraged to apply
Schedule::
Monday to Friday"
Machine Learning Engineer,"Austin, TX",GroupBy Inc.,,Organic,"Machine Learning Engineer -Austin

GroupBy is looking for a Machine Learning Engineer to help us advance the state-of-the-art in e-commerce. Your goal is to build tools and methods to understand customer behavior and recommend/personalize the customer experience for some of the world’s largest retailers. Day to day, you’ll be applying data mining techniques to product data, build models, research new methods, run experiments, and integrate proven methods to run at scale.

Who we are
e-Commerce has come a long way. It feels easy now. Within hours you can set up an online shop and make your first sale.

Despite all the advances though, at a certain scale e-Commerce becomes really hard . What if you want to search 10 million products globally, from hundreds of vendors, in 20 languages, being updated 1000s of times per second? That's where GroupBy comes in.

GroupBy exists to solve the tough problems in e-Commerce: we work with the biggest players in the industry and take on their most complex challenges. We've built a cloud-based, data-driven e-Commerce platform for product data enrichment, intelligent search, personalization, analytics, and other building blocks of a great online shopping experience.

We solve these problems by surrounding ourselves with people who love what they do and are given the freedom to excel at it. Our team is comprised of passionate, innovative thinkers who work together to create groundbreaking products. We like working with awesome people and we like helping these people become even better.

We are very proud of the culture and diversity at GroupBy and encourage anyone from any background to apply. You will be part of a company with open office spaces, free weekly lunches, monthly social events, a closet full of snacks and beverages, and flexible hours. We invest in your growth as a professional with open workshops and company-funded training for events and attending conferences - after all, you're here to solve tough problems!

Learn more about who we are by visiting www.groupbyinc.com
[http://www.groupbyinc.com/]

The Ideal candidate is
Comfortable with freedom and autonomy: you own your work and do what it takes to drive it forward while meeting product roadmap timelines.
Independently able to learn new technologies, prototype and propose software design and solutions.
Able to think innovatively about our products and how to improve them.
You must have
A bachelor’s degree “STEM” field (Science, Technology, Engineering, or Mathematics) (or equivalent work experience).
4+ years of experience as a full-time developer in an agile software development setting.
Proficiency in Python and SQL, with prior professional experience.
An understanding of machine learning fundamentals and some practical experience productionalizing machine learning pipelines (Airflow, Kubeflow, MLflow, etc..).
Experience with NLP libraries and deep learning libraries such as Keras and/or TensorFlow.
Familiarity with cloud technologies and cloud services (preferably Google Cloud Platform, alternatively AWS or Azure) and microservices architecture.
Excellent communication skills; you will work cross-functionally across multiple teams
Nice to have
Master’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics) or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics).
Worked previously on recommendation system problems.
Exposure to one or more of the following: JavaScript / Typescript, Java, Scala, Go, Bash/Shell scripting.
Understanding of A/B testing methodologies and how to statistically evaluate Machine Learning models.
Ability to perform data analysis.
Basic understanding of Docker and Kubernetes.
Understanding of data warehousing concepts, ETL strategies and best practices.
We thank all candidates who applied but only those selected for an interview will be contacted."
Data Scientist - Nationwide Opportunities,"Austin, TX 78758 (North Austin area)","Amazon Web Services, Inc.",,Organic,"A Bachelor or Masters Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.) or equivalent experience
4+ years of industry experience in predictive modeling, data science and analysis
Previous experience in a ML or data scientist role and a track record of building ML or DL models
Experience using Python and/or R
Experience using ML libraries, such as scikit-learn, caret, mlr, mllib
Experience in writing and tuning SQL
Experience with SparkML
Experience working with GPUs to develop model
Experience handling terabyte size dataset
Experience using data visualization tools

Excited by using massive amounts of data to develop Machine Learning (ML) and Deep Learning (DL) models? Want to help the largest global enterprises derive business value through the adoption of Artificial Intelligence (AI)? Eager to learn from many different enterprise’s use cases of AWS ML and DL? Zealous to be key part of Amazon, who has been investing in Machine Learning for decades, pioneering and shaping the world’s AI technology?

At Amazon Web Services (AWS), we are helping large enterprises build ML and DL models on the AWS Cloud. We are applying predictive technology to large volumes of data and against a wide spectrum of problems. Our Professional Services organization works together with our AWS customers to address their business needs using AI.

AWS Professional Services is a unique consulting team. We pride ourselves on being customer obsessed and highly focused on the AI enablement of our customers. If you have experience with AI, including building ML or DL models, we’d like to have you on our team. You will get to work with an innovative company, with great teammates, and have a lot of fun helping our customers.

This role will focus specifically on AWS’ most complex and largest customers in the world to help solve a wide range of business problems. Consultants will provide deep and broad insight to customers and partners to help remove constraints that prevent them from leveraging AWS services to create strategic value.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of AI.

Major responsibilities include:
Understand the customer’s business need and guide them to a solution using our AWS AI Services, AWS AI Platforms, AWS AI Frameworks, and AWS AI EC2 Instances .
Assist customers by being able to deliver a ML / DL project from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
Use Deep Learning frameworks like MXNet, Caffe 2, Tensorflow, Theano, CNTK, and Keras to help our customers build DL models.
Use SparkML and Amazon Machine Learning (AML) to help our customers build ML models.
Work with our Professional Services Big Data consultants to analyze, extract, normalize, and label relevant data.
Work with our Professional Services DevOps consultants to help our customers operationalize models after they are built.
Assist customers with identifying model drift and retraining models.
Research and implement novel ML and DL approaches, including using FPGA.
This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed.

Note: If you do not live in a market where we have an open Data Scientist position, please feel free to apply. Our Data Scientists can live in any location that has an AWS office.

PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
4+ years of industry experience in predictive modeling and analysis
Skills with programming languages, such as Java or C/C++
Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations
Consulting experience and track record of helping customers with their AI needs
Publications or presentation in recognized Machine Learning, Deep Learning and Data Mining journals/conferences
Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, & EMR
Combination of deep technical skills and business savvy enough to interface with all levels and disciplines within our customer’s organization
Demonstrable track record of dealing well with ambiguity, prioritizing needs, and delivering results in a dynamic environment
Experience diving into data to discover hidden patterns
Able to write production level code, which is well-written and explainable

Amazon is an Equal Opportunity Employer – Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age."
"Sr. Manager, Data Science","Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
You understand that the best managers serve their teams by removing roadblocks and giving individual contributors autonomy and ownership. You have high standards and will take pride in Indeed and push teammates to be better. You have delivered challenging technical solutions at scale. You have led Data Science or Engineering teams, and earned the respect of talented practitioners. You are equally happy talking about deep learning and statistical inference, as you are brainstorming about practical experimental design and technology career development. You love being in the mix technically while providing leadership to your teams.

Requirements
Significant prior success as a Data, Product, or Decision Scientist working on challenging problems at scale
Master’s or PhD., with advanced coursework in statistics, machine learning, programming, or related skills
5+ years of industry experience, with expertise in statistical modeling and/ or machine learning
The ability to guide a team to achieve important goals together
Expertise in machine learning and statistical modeling
Strong ability to code in Python
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring
Strong desire to solve tough problems with scientific rigor at scale
An understanding of the value derived from getting results early and iterating
Ability to write and present results to both technical and non-technical audiences
Strong ability to coach Data Scientists, helping them improve their skills and grow their careers
Passion to answer Product/Engineering questions with data
We get excited about candidates who can:
Program using R, Python, Java, or C++
Perform big data modeling work: Hadoop, Pig, Scala, Spark
Fish for data: SQL, Pandas, MongoDB
Deploy Data Science solutions: Java, Python, C++
Can communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Fixed Income Data Engineer,"Austin, TX","Amherst Holdings, LLC",,Organic,"Fixed-Income Data Engineer – Austin, TX
Amherst is revolutionizing the way U.S. real estate is priced, managed and financed in order to unlock opportunities for all market participants. Driven by data, analytics, and technology, Amherst has a 20-year history of anticipating where the next risks and opportunities are likely to emerge and designing actionable strategies for investors to capitalize on opportunities across residential real estate, commercial real estate and public securities. Amherst, along with its affiliates and subsidiaries, has more than 900 employees, $5 billion under management and approximately $15 billion under advisement and oversight. www.amherst.com.
We are looking for a Fixed-Income Data Engineer who is self-motivated, output-oriented individual with strong technical skills who is driven by intellectual curiosity to understand the complexities of financial markets and has experience with the Agency MBS market. The individual will have opportunities to be part of high-level meetings with senior members of the investment teams and have a direct impact on the company's strategy and success.
Responsibilities:
Work collaboratively on projects and analyses utilizing specialized quantitative skills to generate value-added insights and provide data-driven solutions to enhance investment outcomes for the Agency MBS desk.
Drive and use relational-based database technologies and Big Data platforms to research new and innovative techniques and methods to solve problems in support of investment decision making for fixed income.
Support deep analysis of investment strategies, create new quantitative measures, and contribute to new investment strategies.
Develop business acumen to bring an informed perspective to investment management teams.
Use communication and interpersonal skills to integrate with the portfolio management teams. Tailor communication of complex concepts to the audience.
Participate in special projects and perform other duties as assigned.
Qualifications
Graduate degree in a quantitative/analytical field such as Financial Engineering or Computer Science.
Minimum of 3–5 years of experience as a Fixed Income desk quant or equivalent combination of education/training.
Knowledge of capital markets and investment concepts. Knowledge of Agency MBS preferred.
Excellent interpersonal and communication skills.
Strong proficiency in computer programming, such as Python, C#, C++, C, R, and Big Data related technologies.
Strong proficiency in SQL related technologies, such as Microsoft SQL Server, Oracle, MySQL, Hive, Presto, etc.
Ability to work independently and in a team environment.
Demonstrates a high degree of motivation.
BONUS: Intex modeling/data experience
What We Offer:
Amherst’s WeWork office is located on Barton Springs Rd. near the heart of downtown Austin and within walking distance of Lady Bird Lake.
A competitive compensation package, annual bonus, 401k match
Flexible PTO, 8 paid holidays
Employer-paid benefits (medical, dental, vision, health savings account)
Stellar colleagues with proven track records
Parking pass provided (parking located in the Palmer Events Center across the street)
Free sodas, kombucha, cold brew, and snacks
Monthly lunch stipends and breakfast tacos on Thursdays!
Monthly/Weekly office events!
Amherst is proud to be an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status, and encourage all applicants to apply.
Job Type: Full-time
Experience:
Fixed Income desk quant: 3 years (Required)
Education:
Master's (Required)
Additional Compensation:
Bonuses
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Paid time off"
Data Engineer,"Austin, TX 78735 (West Oak Hill area)","Buzz Points, Inc.",,Organic,"Company Description
What is Buzz Points?
Buzz Points® is revolutionizing the rewards industry for community banks and credit unions. As consumers grow weary of tired “points programs” with catalogs of undesirable merchandise for rewards, Buzz Points is leading the way for community financial institutions to differentiate and compete with the mega-banks and their eye-catching incentives.
The Buzz Points next-generation rewards platform offers the most advanced customer engagement and loyalty program in the industry. Community banks and credit unions utilize the innovative platform to offer exciting rewards for profitable behaviors on credit cards, debit cards and account-based behavioral activities, all while improving customer engagement and driving revenue.
Our holistic solution uses incentives to engage customers, support communities and “level the playing field” between community banks and credit unions and their mega-bank competition. It generates real revenue with a powerful combination of data-driven insights and unparalleled user experience to deliver undeniable bottom line results.
Buzz Points is a fast-growing company with over 50 financial institution customers in 28 states today. Our investors include Lead Edge Capital, KEC Ventures, Greycroft Partners, Wild Basin Investments, Daylight Partners, Metamorphic Partners, Discover Financial Services/PULSE and more.

Job Description
Buzz Points® is looking for a Data Engineer with a track record of playing an integral role in handling the design and construction of scalable management systems. The Data Systems and Reporting Analyst will join our Engineering team and report directly to the Director of Engineering.
WHAT YOU’LL DO:
It’s an exciting time at Buzz Points. Our platform has evolved around cloud centric technologies and we need capable engineers who understand the value of data. The role of a data systems and reporting analyst is a supporting one, but it is also an extremely vital one.
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company and compliance standards, as well as research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.
In order to be stand out as a candidate, you should express humility and patience. Data engineering is about building the underlying infrastructure, and so being able to pass the limelight to someone else is imperative. Furthermore, being able to listen to your colleagues is essential. Essential duties will include:
Design, construct, install, test and maintain data management systems in AWS
Build high-performance algorithms, predictive models, and prototypes.
Ensure that all systems meet the business/company requirements as well as industry practices.
Defines and develops standard reports for key data metrics.
Develops custom and ad-hoc reports based on requirements provided by departments and customers.
Integrate up-and-coming data management and software engineering technologies into existing data structures.
Develop set processes for data mining, data modeling, and data production.
Create custom software components and analytics applications.
Research new uses for existing data.
Employ an array of technological languages and tools to connect systems together.
Collaborate with members of your team (eg, data architects, the IT team, data scientists) on the project’s goals.
Install/update disaster recovery procedures.
Recommend different ways to constantly improve data reliability and quality.
Special projects and other duties will be assigned as needed.
Represent the Buzz Points brand and mission with honesty, integrity, and professionalism.

Qualifications
KEY PERSONALITY TRAITS:
Fit with our culture and natural leadership is important to the success of this role.
You must have the high energy, tenacity, and positivity. You must be high integrity, laser focused, and have a “need to succeed” at whatever you do.
Exercise a commanding and inspiring team collaboration style;
Constantly elevate and improve methods and be a natural analytical and diagnostic problem solver;
Ability to manage multiple initiatives while working independently.
WHAT’S REQUIRED:
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics statistics and 3 years of applicable work experience.
An understanding of AWS technologies such as S3, SQS, Lambda, AWS Glue, Athena, RDS DMS, DynamoDB, and Quick Sight are essential.
Proficiency in Python and bash or equivalent programming languages. Node.js is a plus.
It’s a bonus if you understand Kinesis or have setup event streaming for data pipelines.
An understanding of PostgreSQL or equivalent relational databases.
Experience in a related field with real-world skills and testimonials from former employees.
Possible work experience and proof of technical expertise.
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
Ability to approach data organization challenges while keeping an eye on what’s important.
Self-Starter/Motivator who works well with others.
Customer-centric approach to work.
Experience working with community banks and credit unions is a plus.
Experience in similar roles with a fast-growing small business marketing or rewards program a plus.
Thrives in a high-tech, fast-paced, team-oriented environment.
Enthusiasm, positive attitude, self-motivation, and strong work ethic.
Organizational skills and attention to detail, as well as experience in change management and project management experience, are crucial.

DATA ENGINEERING FAQ:
What is included in the daily work of a data engineer?
A day on the job in data engineering consists of handling data within the organization, data transformation, and maintaining systems. Data query might also crop up quite a bit, as you’ll be asked by colleagues and customers to create reports.
Which technical languages should I learn to increase my chances of getting a job as a data engineer?
You should be well-versed in statistics, machine learning techniques, mathematics, and SQL databases. Python is also the most widely used programming language across the board when it comes to data engineering and we are migrating most of our legacy scripts to this language. Furthermore, a problem-solving, analytical knowledge of databases will also be a great asset.
What problems might data engineer run into?
Data engineering is probably the most research-extensive role in the organization, and so these roles come across a lot of problems. Some of these problems include the consideration of whether or not cloud storage will scale and knowing how long it will take to make it possible, as well as understanding why an import job failed for one of our internal or external stakeholders. Data engineering is part trial and error, and it is your job to diagnose and fix any failures that might occur.
Additional Information
BENEFITS:
Work/Life Balance
Sponsored Volunteer Days
Employee Events
Stocked Kitchen with drinks and snacks
Innovative Company culture
401K plan
Competitive Pay - Base + Annual Bonus Opportunity
Stock options grants
Buzz Points is an equal opportunity employer. All final candidates will be subject to a pre-employment drug screen and background check.
To apply, please submit resume and salary requirements."
Fixed-Income Data Engineer,"Austin, TX 78704 (South Lamar-South Congress area)",Amherst,,Organic,"Fixed-Income Data Engineer – Austin, TX
Amherst is revolutionizing the way U.S. real estate is priced, managed and financed in order to unlock opportunities for all market participants. Driven by data, analytics, and technology, Amherst has a 20-year history of anticipating where the next risks and opportunities are likely to emerge and designing actionable strategies for investors to capitalize on opportunities across residential real estate, commercial real estate and public securities. Amherst, along with its affiliates and subsidiaries, has more than 900 employees, $5 billion under management and approximately $15 billion under advisement and oversight. www.amherst.com.
We are looking for a Fixed-Income Data Engineer who is self-motivated, output-oriented individual with strong technical skills who is driven by intellectual curiosity to understand the complexities of financial markets and has experience with the Agency MBS market. The individual will have opportunities to be part of high-level meetings with senior members of the investment teams and have a direct impact on the company's strategy and success.
Responsibilities:
Work collaboratively on projects and analyses utilizing specialized quantitative skills to generate value-added insights and provide data-driven solutions to enhance investment outcomes for the Agency MBS desk.
Drive and use relational-based database technologies and Big Data platforms to research new and innovative techniques and methods to solve problems in support of investment decision making for fixed income.
Support deep analysis of investment strategies, create new quantitative measures, and contribute to new investment strategies.
Develop business acumen to bring an informed perspective to investment management teams.
Use communication and interpersonal skills to integrate with the portfolio management teams. Tailor communication of complex concepts to the audience.
Participate in special projects and perform other duties as assigned.
Qualifications
Graduate degree in a quantitative/analytical field such as Financial Engineering or Computer Science.
Minimum of 3–5 years of experience as a Fixed Income desk quant or equivalent combination of education/training.
Knowledge of capital markets and investment concepts. Knowledge of Agency MBS preferred.
Excellent interpersonal and communication skills.
Strong proficiency in computer programming, such as Python, C#, C++, C, R, and Big Data related technologies.
Strong proficiency in SQL related technologies, such as Microsoft SQL Server, Oracle, MySQL, Hive, Presto, etc.
Ability to work independently and in a team environment.
Demonstrates a high degree of motivation.
BONUS: Intex modeling/data experience
What We Offer:
Amherst’s WeWork office is located on Barton Springs Rd. near the heart of downtown Austin and within walking distance of Lady Bird Lake.
A competitive compensation package, annual bonus, 401k match
Flexible PTO, 8 paid holidays
Employer-paid benefits (medical, dental, vision, health savings account)
Stellar colleagues with proven track records
Parking pass provided (parking located in the Palmer Events Center across the street)
Free sodas, kombucha, cold brew, and snacks
Monthly lunch stipends and breakfast tacos on Thursdays!
Monthly/Weekly office events!
Amherst is proud to be an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We do not discriminate on the basis of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status, and encourage all applicants to apply."
MDAT Data Engineer,"Austin, TX",Accenture,,Organic,"Do you want to gain valuable skills and experience working as a contractor?

ACCENTURE CONTRACTOR EXCHANGE Solves clients’ toughest challenges by providing unmatched services in strategy, consulting, digital, technology, operations and security. Develop and enhance your skills and experience, working across diverse teams, projects, and industries.

Project Description:
We are seeking a MDAT Data Engineers for our client in Austin, TX
Must be local or willing to relocate at own expenses
This is a contract opportunity that does not offer sponsorship nor in the future
Must be willing to work on W2

Responsibilities:
Support a limited number of Client data warehouse sub-systems, works on multiple assignments concurrently, and completes work in queue by assigned due dates with limited supervision when working in an area where they have existing experience
Performs design and development activities, testing, and deployments in an agile product delivery environment
Works in close cooperation with project managers and other functional team members to form a team effort in the development
Research and resolve simple to moderately complex issues as assigned
Use one or more intermediate technical skills (Ex. SQL, data warehouse concepts, ETL & OLAP reporting, etc.) and actively works to expand technical skills to increase support responsibilities
Combine technical skills with knowledge of Texas Medicaid systems and business processes to deliver effective solutions
Proactively provide status on assignments in a clear and concise manner highlighting key activities impacting solution delivery
Identify problems and escalates to the supervisor's attention with sufficient lead time to avert crises
Participate in pager/on-call support, deployment of production releases, and introduction of new services into the production environment
Consider a SME for at least one Client data warehouse sub-system and actively works to expand SME to support additional sub-systems
Produces work products of high quality that demonstrate use of applicable standards
Assists in peer-reviewing the work of others
Limited client interaction both written and verbal with supervision
Report time biweekly into appropriate time tracking mechanism in an accurate & timely manner consistent with project & employer guidelines
Proactively complete all compliance training courses in a timely manner

Minimum Qualifications:
Minimum 2 years of Korn and/or Bash Shell Scripting experience
Minimum 2 years of Linux and/or Unix experience
Minimum 2 years of Oracle experience

Preferred Qualifications:
Experience Developing, Testing and Managing complete ETL/ELT solutions
Experience supporting Data Warehouse Systems
Financial Analysis
Problem Solving
Business Intelligence tools

Keywords:
Oracle Applications PL/SQL


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
Data Scientist,"Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.

Austin Base Salary Range: 106,000 - 128,000 USD per year

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
Requirements

BS in Computer Science, Statistics, Mathematics or a closely related quantitative field
2 years of professional industry experience in Data Science, Business Analytics, or Data Analysis
Expertise in machine learning and statistical modeling
Passion to answer Product/Engineering questions with data
Strong ability to code in Python
We get excited about candidates who:
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring of data science products
Are proficient in small data modeling work: Python, R, Julia, Octave
Are proficient in big data modeling work: Hadoop, Pig, Scala, Spark
Can fish for data: SQL, Pandas, MongoDB
Deploy data science solutions: Java, Python, C++
Communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Data Engineer,"Austin, TX",Seen by Indeed,,Organic,None
Data Warehouse Engineer,"Austin, TX",Seen by Indeed,,Organic,None
MDAT Data Engineer,"Austin, TX",Accenture,,Organic,"Do you want to gain valuable skills and experience working as a contractor?

ACCENTURE CONTRACTOR EXCHANGE Solves clients’ toughest challenges by providing unmatched services in strategy, consulting, digital, technology, operations and security. Develop and enhance your skills and experience, working across diverse teams, projects, and industries.

Project Description:
We are seeking a MDAT Data Engineers for our client in Austin, TX
Must be local or willing to relocate at own expenses
This is a contract opportunity that does not offer sponsorship nor in the future
Must be willing to work on W2

Responsibilities:
Support a limited number of Client data warehouse sub-systems, works on multiple assignments concurrently, and completes work in queue by assigned due dates with limited supervision when working in an area where they have existing experience
Performs design and development activities, testing, and deployments in an agile product delivery environment
Works in close cooperation with project managers and other functional team members to form a team effort in the development
Research and resolve simple to moderately complex issues as assigned
Use one or more intermediate technical skills (Ex. SQL, data warehouse concepts, ETL & OLAP reporting, etc.) and actively works to expand technical skills to increase support responsibilities
Combine technical skills with knowledge of Texas Medicaid systems and business processes to deliver effective solutions
Proactively provide status on assignments in a clear and concise manner highlighting key activities impacting solution delivery
Identify problems and escalates to the supervisor's attention with sufficient lead time to avert crises
Participate in pager/on-call support, deployment of production releases, and introduction of new services into the production environment
Consider a SME for at least one Client data warehouse sub-system and actively works to expand SME to support additional sub-systems
Produces work products of high quality that demonstrate use of applicable standards
Assists in peer-reviewing the work of others
Limited client interaction both written and verbal with supervision
Report time biweekly into appropriate time tracking mechanism in an accurate & timely manner consistent with project & employer guidelines
Proactively complete all compliance training courses in a timely manner

Minimum Qualifications:
Minimum 2 years of Korn and/or Bash Shell Scripting experience
Minimum 2 years of Linux and/or Unix experience
Minimum 2 years of Oracle experience

Preferred Qualifications:
Experience Developing, Testing and Managing complete ETL/ELT solutions
Experience supporting Data Warehouse Systems
Financial Analysis
Problem Solving
Business Intelligence tools

Keywords:
Oracle Applications PL/SQL


Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).

Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.

Accenture is a Federal Contractor and an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.

Equal Employment Opportunity
All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.

Accenture is committed to providing veteran employment opportunities to our service men and women."
Machine Learning Ops Engineer,"Austin, TX 78702 (Govalle area)",Pensa Systems,,Organic,"Job Description
Pensa leverages a variety of Machine Learning (ML) models to recognize Consumer Packaged Goods (CPGs) from videos acquired in live retailer locations. Retail is a naturally fast-paced environment with an ever growing and changing catalogue of CPGs. To ensure we maintain very high recognition accuracy in this dynamic environment, we continuously train, evaluation, and deploy new ML models.
This requires that we have a strong focus on the tooling and process for curating our training data sets and managing both the model and data lifecycles. We are looking to expand our ML team to support this strong focus on managing our data and managing the models we run in our production servers. The ML Ops Engineers work closely with the rest of the ML team to build tooling and process for understanding how the quality of our datasets impact our models, and ultimately how this impacts our overall system accuracy. Our ML Ops Engineers also work closely with our data team to ensure that we are building a strong feedback loop between human-curated datasets and machine trained models. This involves making good decisions about how we leverage our subject matter experts that label training data, and building the right feedback loops to allow our trained models to assist in the dataset management process.
Our ML Ops Engineers are responsible for:
Training, testing, and deploying new models into production and managing the full lifecycle of our production models.
Working with our Data Team to ensure that our annotation specialists have the tools and information to make good decisions about the labeled content they manage to ensure the overall quality of our training datasets.
Managing the process of ingesting new products into our dataset.
Evaluating the performance of our production models to identify when changes need to be made to our training data so that our recognition accuracy remains high.
Working with the ML, Software, and Product Management teams to identify requirements for improving our labeling, evaluation, and deployment tools and processes. The ideal candidate will be able to own some of the coding work for these tools.
Supporting our products and customers in a production environment.
Actively supporting our continuous journey of applying “just enough” process so that we can do our best work every day. Strong opinions are encouraged.
Requirements
2 or more years training and managing ML models using real-world data, ideally in a commercial environment with experience supporting a shipping product.
A strong understanding of data ingest and annotation lifecycles, and ideally and understanding of the services offered by the ecosystem of annotation vendors.
Hands-on experience with one of the major ML frameworks such as Tensorflow or PyTorch.
Hands-on experience working in a Unix/Linux environment.
Familiarity with the major ML-as-a-Service offerings such as AWS SageMaker, Google MLEngine, or Azure Machine Learning.
2 or more years of recent experience with Python.
Direct experience with and RDBMS such as PostgreSQL or MySQL.
Bachelor's degree in any technical field. An advanced degree is a plus.
About Pensa Systems
Pensa is a local Austin technology company and a leading innovator in autonomous perception systems for global retail inventory visibility. Our system uses breakthrough technology including artificial intelligence, autonomous drones and computer vision to understand what is on store shelves. We have snacks in the kitchen, beer in the fridge and flexible work hours. Although we work hard, we don’t get too wrapped up with protocol or bureaucracy. We appreciate the diversity of all stripes and are an equal opportunity employer. We are building really cool things that are disrupting multi-trillion-dollar global industries. If you enjoy working with cutting-edge technology and operating in a fast-paced, high-impact environment, then Pensa is the place for you. To learn more about us, please visit www.pensasystems.com and stay connected via Twitter and LinkedIn.
Job Type: Full-time
Experience:
Dev Ops: 3 years (Required)
Machine Learning: 1 year (Required)
Education:
Bachelor's (Required)"
Data Engineer,"Austin, TX 78735 (West Oak Hill area)","Buzz Points, Inc.",,Organic,"Buzz Points® is looking for a Data Engineer with a track record of playing an integral role in handling the design and construction of scalable management systems. The Data Engineer will join our Engineering team and report directly to the Director of Engineering.
What is Buzz Points?
Buzz Points® is revolutionizing the rewards industry for community banks and credit unions. As consumers grow weary of tired “points programs” with catalogs of undesirable merchandise for rewards, Buzz Points is leading the way for community financial institutions to differentiate and compete with the mega-banks and their eye-catching incentives.
The Buzz Points next-generation rewards platform offers the most advanced customer engagement and loyalty program in the industry. Community banks and credit unions utilize the innovative platform to offer exciting rewards for profitable behaviors on credit cards, debit cards and account-based behavioral activities, all while improving customer engagement and driving revenue.
Our holistic solution uses incentives to engage customers, support communities and “level the playing field” between community banks and credit unions and their mega-bank competition. It generates real revenue with a powerful combination of data-driven insights and unparalleled user experience to deliver undeniable bottom line results.
Buzz Points is a fast-growing company with over 50 financial institution customers in 28 states today. Our investors include Lead Edge Capital, KEC Ventures, Greycroft Partners, Wild Basin Investments, Daylight Partners, Metamorphic Partners, Discover Financial Services/PULSE and more.
What you’ll do:
It’s an exciting time at Buzz Points. Our platform has evolved around cloud centric technologies and we need capable engineers who understand the value of data. The role of a data systems and reporting analyst is a supporting one, but it is also an extremely vital one.
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company and compliance standards, as well as research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.
In order to be stand out as a candidate, you should express humility and patience. Data engineering is about building the underlying infrastructure, and so being able to pass the limelight to someone else is imperative. Furthermore, being able to listen to your colleagues is essential. Essential duties will include:
· Design, construct, install, test and maintain data management systems in AWS
· Build high-performance algorithms, predictive models, and prototypes.
· Ensure that all systems meet the business/company requirements as well as industry practices.
· Defines and develops standard reports for key data metrics.
· Develops custom and ad-hoc reports based on requirements provided by departments and customers.
· Integrate up-and-coming data management and software engineering technologies into existing data structures.
· Develop set processes for data mining, data modeling, and data production.
· Create custom software components and analytics applications.
· Research new uses for existing data.
· Employ an array of technological languages and tools to connect systems together.
· Collaborate with members of your team (eg, data architects, the IT team, data scientists) on the project’s goals.
· Install/update disaster recovery procedures.
· Recommend different ways to constantly improve data reliability and quality.
· Special projects and other duties will be assigned as needed.
· Represent the Buzz Points brand and mission with honesty, integrity, and professionalism.
Key Personality Traits:
Fit with our culture and natural leadership is important to the success of this role.
You must have the high energy, tenacity, and positivity. You must be high integrity, laser focused, and have a “need to succeed” at whatever you do.
Exercise a commanding and inspiring team collaboration style;
Constantly elevate and improve methods and be a natural analytical and diagnostic problem solver;
Ability to manage multiple initiatives while working independently.
What’s required:
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics statistics and 3 years of applicable work experience.
An understanding of AWS technologies such as S3, SQS, Lambda, AWS Glue, Athena, RDS DMS, DynamoDB, and Quick Sight are essential.
Proficiency in Python and bash or equivalent programming languages. Node.js is a plus.
It’s a bonus if you understand Kinesis or have setup event streaming for data pipelines.
An understanding of PostgreSQL or equivalent relational databases.
Experience in a related field with real-world skills and testimonials from former employees.
Possible work experience and proof of technical expertise.
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
Ability to approach data organization challenges while keeping an eye on what’s important.
Self-Starter/Motivator who works well with others.
Customer-centric approach to work.
Experience working with community banks and credit unions is a plus.
Experience in similar roles with a fast-growing small business marketing or rewards program a plus.
Thrives in a high-tech, fast-paced, team-oriented environment.
Enthusiasm, positive attitude, self-motivation, and strong work ethic.
Organizational skills and attention to detail, as well as experience in change management and project management experience, are crucial.
Data Engineering FAQ:
What is included in the daily work of a data engineer?
A day on the job in data engineering consists of handling data within the organization, data transformation, and maintaining systems. Data query might also crop up quite a bit, as you’ll be asked by colleagues and customers to create reports.
Which technical languages should I learn to increase my chances of getting a job as a data engineer?
You should be well-versed in statistics, machine learning techniques, mathematics, and SQL databases. Python is also the most widely used programming language across the board when it comes to data engineering and we are migrating most of our legacy scripts to this language. Furthermore, a problem-solving, analytical knowledge of databases will also be a great asset.
What problems might data engineer run into?
Data engineering is probably the most research-extensive role in the organization, and so these roles come across a lot of problems. Some of these problems include the consideration of whether or not cloud storage will scale and knowing how long it will take to make it possible, as well as understanding why an import job failed for one of our internal or external stakeholders. Data engineering is part trial and error, and it is your job to diagnose and fix any failures that might occur.
Job Type: Full-time
Experience:
Data: 3 years (Preferred)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Flexible schedule
Parental leave"
Product Scientist,"Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.

Austin Base Salary Range: 116,000 - 142,000 USD per year

Your job:
One of our core principles is a dedication to data-driven decision-making. To do that well, we need data scientists with a strong product sensibility to work alongside our product managers and technical leads.

Our Product Science team is a part of the Indeed Data Science group. While machine learning is one tool in our toolbox, Product Scientists use a variety of skills with the goal of driving business impact using whatever tools necessary.

Responsibilities
Help people get jobs!
Use quantitative analysis, data mining, and machine learning techniques to understand how hundreds of millions of jobseekers and employers are interacting on Indeed, and how those interactions are reflected in our data.
Work alongside product managers and engineering teams to help guide tactical and strategic product decisions.
Design and use statistically sound methodologies for evaluating hundreds of tests on thousands of web pages across dozens of business-relevant metrics.
Work alongside other data scientists and software engineers to expand Indeed's catalog of tools, techniques, and best practices for manipulating and interpreting terabytes of product data.
Share your work to a diverse audience across a variety of media. Help us promote and practice transparency by highlighting failures that we learn from as much as successes.
Work across a wide range of related areas- data extraction and cleansing, feature engineering, machine learning, exploratory analysis, data quality analysis, experimental analysis.
About you:
Requirements
MS in Computer Science, Statistics, Mathematics or a closely related quantitative field
3 years of professional industry experience in Data Science, Business Analytics, or Data Analysis * Experience coding in Python, R or another advanced data programming language
Strong communication and collaboration skills
Ability to write and present results to both technical and non-technical audiences
Driven to help their teammates and Indeed’s products
Experience designing and conducting complex projects
What we’d love to see (but isn’t required):
Master’s or PhD., with advanced coursework in statistics, machine learning, programming, or related skills
Relevant experience (including internships and/or research) in Business Analytics, Data Analysis, Product Management, Data Science, or related fields
In-depth knowledge and experience within consumer behavior, the consumer marketplace, and/or eCommerce fields
Experience building and/or pulling data using SQL
Production experience with machine learning and other advanced statistical methods
Deep understanding of designing and implementing A/B tests, and advanced extensions
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
"Data Scientist - Sports Analytics (Full-Time, Entry-Level, S...","Austin, TX 78703 (Old West Austin area)",Zelus Analytics,,Organic,"We are seeking entry-level data scientists with a passion for sports to develop the quantitative models that power our world-leading sports intelligence platform. The projected start date would be the summer of 2020.
Zelus Analytics combines a fast-growing startup environment with a research-focused culture. We pride ourselves on offering our employees the freedom and mentorship to develop and expand their analytical skills. Our goal is to help the professional teams in our exclusive partner network compete and win championships. In so doing, we hope to create a new path for highly talented data scientists to push the cutting edge of sports analytics.
Job Functions:
Statistical modeling and quantitative analysis to support one or more research projects focused on player evaluation and in-game strategy
Developing, validating, and automating quantitative models using statistics, machine learning, optimization, and simulation
Attending sports analytics conferences and reviewing public research
Preparing reports and presentations to share model specifications and validation results
Performing ad hoc data analysis to support our partner teams
Other duties and responsibilities as assigned
Requirements:
B.S., M.S., or Ph.D. in applied mathematics, statistics, computer science, operations research, or a related quantitative field
Industry or research experience with applied mathematical and predictive modeling (statistics, machine learning, optimization, and/or simulation)
Experience working with sports data, through academic research, independent projects, and/or prior internships
Fluency with mathematical and statistical programming (Python and/or R)
Familiarity with relational databases and cloud-based computing
Desire to work in a collaborative team environment
Enthusiasm for sports analytics and knowledge of recent public advances in the sports analytics research community
You should definitely apply if:
You are passionate about sports analytics and relish the opportunity to explore complex, private data sets on behalf of professional sports teams
You would enjoy the exciting pace and upside of working for a tech startup in one of the best places to live in the U.S.
In addition to competitive salaries, our compensation packages include equity and benefits, such as a 401(k) plan and unlimited PTO, that allow us to compete with professional sports teams for the best available talent. Zelus Analytics is committed to creating a diverse and inclusive work environment where all of our employees can thrive.
Job Type: Full-time
Salary: $70,000.00 to $100,000.00 /year
Experience:
Predictive Modeling: 1 year (Preferred)
R: 1 year (Preferred)
Python: 1 year (Preferred)
Education:
Bachelor's (Required)
Location:
Austin, TX 78703 (Required)
Work authorization:
United States (Required)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Flexible schedule
Parental leave
Relocation assistance
This Job Is Ideal for Someone Who Is:
Achievement-oriented -- enjoys taking on challenges, even if they might fail
Autonomous/Independent -- enjoys working with little direction
Innovative -- prefers working in unconventional ways or on tasks that require creativity"
Data Engineer,"Austin, TX","Aunt Bertha, a Public Benefit Corp.",,Organic,"Our Mission: To connect all people in need and the programs that serve them (with dignity and ease).
Aunt Bertha picks up where Uncle Sam leaves off by making it easy to find and apply for government and charitable social service programs. By organizing the world's human service program information, we make it easy for people in need and the people who help them to find help in seconds on www.auntbertha.com.
We are looking for people who are driven to make the world a drastically better place and want to join our small group of thoughtful, committed citizens because they believe, as Margaret Mead said, ""Never doubt that a small group of thoughtful, committed citizens can change the world; indeed, it's the only thing that ever has.""
Please note: If our mission doesn't strike a chord with you that is OK. But please consider not applying. We are seeking people who come on fire after learning about what we do.
What We Need Your Help Doing: The Data Engineer is essential to helping Aunt Bertha design, build and maintain a scalable data platform. This role is key in automating data processes to enable focusing on business value while eliminating toil; taking a lead role in schema design, indexing, data transformation, custom SQL development and other data-centric development tasks; working with engineering and infrastructure stakeholders to design and improve our database architecture; and working with our data architect to advocate for and introduce new technologies to solve data-related challenges and position us to make significant advances in new areas of data strategy.
Key Responsibilities:
Manage and optimize existing MySQL databases (schemas, indexing, security)
Design solutions to data-centric issues like performance, scalability and manageability
Use knowledge of various approaches to managing data (e.g. relational, document-based, columnar, etc.) to propose and design solutions that best fit the business needs
Write code for new system features, especially those related to data or reporting. There will be a heavy emphasis on implementing ETLs with proficiency in SQL and Python.
Work with the wider engineering team to validate and implement product-driven schema changes
Troubleshoot database issues and performance during development and testing, and create appropriate fixes
Follow established processes for documentation, testing and deployment of data-related features
Handle customer-reported data-related bugs and change requests
We are looking for someone who:
Is driven by the mission of helping others through building amazing software
Is competent with the languages and tools needed to develop database software
Keeps current with new data technologies and matches the right tool to the problem
Loves automating as much as possible
Communicates effectively in writing and speaking
Nice-to-have skills:
Experience with git
Familiarity with Pentaho or similar ETL tools
Experience in Google Cloud Platform or similar cloud-based infrastructure
Experience with Ansible or other infrastructure-as-code solutions
Apply Now! We are selecting from a broad field of candidates. If you are interested in learning more and think you have what it takes to win, please respond to this job posting with:
Your résumé
A short cover letter in which you tell us who you are, what you want to achieve in life and how this job will help you get there, and why Aunt Bertha should strongly consider a deeper conversation with you.
A cover letter is required! We get a lot of applicants, and only those who are truly engaged with our company mission will likely move forward. Additionally, please provide samples or links to any prior work that demonstrate your skill set, if available (e.g. a Github repo, portfolio page, etc.)
Physical Demands & Work Environment: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Some travel may be required.
We are proud to be an Equal Opportunity Employer and value diversity on our team.
Job Type: Full-time
Experience:
data/ETL: 3 years (Required)
Location:
Austin, TX (Required)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Parental leave
Other
Visa Sponsorship Potentially Available:
No: Not providing sponsorship for this job"
Big Data Engineer (Hadoop/Machine Learning/Cloudera/Databric...,"Austin, TX",Derotek,,Organic,"Job Description
Who we are looking for:
An accomplished Senior Software Analytic Engineer with demonstrated success designing, delivering and maintaining complex highly performant Secure Data Analytic (SDA) Environments for the Fortune 100. Along with technical leadership skills to ensure client engagement success through a highly collaborative team environment.
How you’ll make an impact:
· Design, deploy and maintain SDA platforms.
· Provide Data Flow Management based on NiFi, Streamsets along with various open source ingest and caching tools.
· Perform Analytic Processing.
· Visualize and Explore data.
· Design, deploy and maintain scalable storage and query environments.
· Work with various Public Cloud Providers and Private Cloud Technologies.
Qualifications
Qualifications for success:
Required Experience:
· Experience with Spark, Hadoop, or similar analytical tools
· Experience with standard IDE such as Eclipse, Intellij
· Knowledge of standard ticketing and version control suites: Git, Subversion, Jira, Confluence, etc.
· Experience with a variety of build tools such as gradle, sbt, ant, or maven
· Experience with linux systems and scripting languages: bash, python, SQL, etc.
· Understands and can write test driven analytics with tools like JUnit or Mockito
· Has used inversion of control systems like Guice or Spring
Recommended Experience:
· Familiarity with HDP, Cloudera or similar big data processing platforms
· Experience with HDF or similar data transport technologies
· Machine Learning exposure with technology such as Spark MLLib or Apache Spot
Required skills:
· Ability to deep dive in to complex problems on established environments
· Experience with functional programming, ideally in Scala, Python, and/or JavaScript
· Documentation. It's okay to hate documenting things. It's not okay to leave things undocumented.
Recommended skills:
· Leadership experience driving success from an individual to small team to and multi team environments in disparate locations
Job Type: Full-time
Salary: $110,000.00 to $140,000.00 /month
Experience:
Cloudera: 1 year (Preferred)
Hadoop: 3 years (Preferred)
Machine Learning: 1 year (Preferred)
Work authorization:
United States (Required)
Additional Compensation:
Bonuses
Work Location:
Fully Remote
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Professional development assistance
Schedule::
Monday to Friday"
Data Analyst,"Austin, TX",SubjectWell,,Organic,"About SubjectWell
SubjectWell is a venture-backed startup on an unstoppable mission to disrupt the antiquated $100 billion dollar clinical trial patient recruitment sector. Almost all clinical trials fall behind schedule, leaving patients unable to access the most promising treatments and pharmaceutical and biotech companies unable to quickly carry their innovations to market. SubjectWell was founded by two entrepreneurs on their third successful startup, to unlock the potential of a true marketplace for clinical trials. We leverage proven data science and performance marketing techniques to hit a hard reset to the massive patient recruitment challenge that sits at the critical nexus of speeding delivery of the best therapeutics to the world.

Here's your chance to really make a difference, both in your career and in the lives of millions.


About the position
This position is for a Data Analyst whose role is to be an expert at understanding SubjectWell's data and to aid various teams in drawing insight. This includes creating dashboards, visualizations, algorithms, and business tools for use across the organization. If you are excited to work with data and to collaborate in figuring out how to rapidly drive improvements based on rich and diverse real-time data, this is a great opportunity to hone your skills.

Responsibilites and Duties
Work with business owners to identify reporting and analysis needs
Design and build the ETL processes for data to be used in reporting
Develop automated tools + dashboards to increase visibility of core KPIs
Facilitate delivery of ad hoc analysis and data requests
Ability to tell a story through data
Ensure data quality, consistency and security

Qualifications and Skills
Bachelor’s Degree in Math, Business, Economics, Computer Science or a related field
High levels of proficiency in SQL and query optimization for MySQL
Extensive experience with Tableau and Tableau Prep
Ability to exercise different problem-solving approaches to analyze data
Sufficient knowledge of probability and statistics to aid teams in understanding the strength of results
Fluent in at least one object-oriented programming language (e.g. Python, Java, Scala or R)

Benefits
Full Medical, Dental, and Vision Benefits
401(k)
Company stock options
Paid time off
Paid holidays
Casual office
Flexible vacation"
Sr. Data Engineer,"Austin, TX",Gravity Technology Solutions,,Organic,"The data engineer will work directly with product and engineering teams to understand data needs and create end-to-end data solutions. The engineer will function as a technical leader developing cutting-edge solutions that manage data pipelines from acquisition to web service delivery.
Required Qualifications:
· Experience as a data engineer or similar role
· Professional software development experience
· Database development experience with relational databases
· Strong work experience with Python scripting or equivalent
· SQL optimization and tuning experience
· Knowledge of advanced analytics tools and data lakes
· Amazon RDS
Nice to have experience:
· Big Data and ML
· Data visualization tools
· AWS RDS PostgreSQL
· AWS Glue, EMR, and Kinesis
We offer Highly competitive salary and benefits including:
· Unlimited PTO and maternity/paternity leave
· Flexible Work Schedules
· Top tier: medical, dental, vision, disability, 401k
Note: Relocation is not available for this role and candidates must be available to interview in-person within 7 days.
Job Type: Full-time
Salary: $130,000.00 to $150,000.00 /year
Experience:
Amazon RDS: 2 years (Preferred)
Python: 2 years (Preferred)
Location:
Austin, TX (Required)
Work authorization:
United States (Required)
Additional Compensation:
Bonuses
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Flexible schedule
Parental leave
This Company Describes Its Culture as:
Detail-oriented -- quality and precision-focused
Innovative -- innovative and risk-taking
Team-oriented -- cooperative and collaborative
This Job Is:
Open to applicants who do not have a college diploma"
Senior Data Scientist,"Austin, TX",Data Quantist,,Organic,"Job requirements/ skills:
Master’s degree with background in Math, Statistics, Operations Research or other quantitative disciplines
6+ years of hands-on experience in machine learning, predictive modeling, survival and consumer lifetime value analysis, clustering algorithms, Map Reduce or other data reduction techniques and product / customer segmentation with large and complex data sets.
Deep expertise in analyzing large, complex, multi-dimensional data sets with combination of tools, including SQL and other ETL tools
Expert level use of of statistical programming tools (R, SAS, SPSS) to create high performing predictive models.
Highly desired: Experience with Python, C/C++, Java. Experience with text mining and unstructured data is a plus.
Test ideas and hypotheses rigorously with drive and passion, develop the story in the data and communicate it to stakeholders. Ability to make presentations and communicate insights effectively using MS Office tools to diverse audiences including senior executives.
Experience with BI and visualization technologies: Tableau, Microstrategy, Crystal Reports, etc."
Data Scientist,"Austin, TX",Cloudflare,,Organic,"About Us

At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world's largest networks that powers trillions of requests per month. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare have all web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was recognized by the World Economic Forum as a Technology Pioneer and named to Entrepreneur Magazine's Top Company Cultures list.

We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!

About the department

Cloudflare is looking to build and grow our Business Intelligence team responsible for building large-scale enterprise data lake and EDW from different sources and enabling various product and business teams such as Marketing, Customer Support, Sales, Finance with key business dashboards/reporting, insights and recommendation models.

About the role

As part of this initiative, we are looking for a strong data scientist to come join Cloudflare and help us drive predictive analytic insights and best practices at scale from the ground up. This is a high visibility role and success in this role comes from marrying a strong data & modeling background with acute product and business acumen to deliver highly strategic and compelling insights that accelerate our business growth and influence our product decisions within Cloudflare. This person will also play a crucial role in hiring and growing the data science team in Austin in a rapid manner.

What we look for: Predictive Modeling techniques, Machine Learning, Model creation and deployment, Storytelling and Visualization, Strong Business & Product acumen, Cross-functional Collaboration, Creative Problem solving, Agile

What you'll do
--------------

Partner and align with business leaders, stakeholders, product managers and internal teams to understand the business and product challenges and goals and address them using predictive analytics in a globally distributed environment.
Understand data landscape i.e tooling, tech stack, source systems etc. and work closely with the data engineering team to improve the data collection and quality.
Understand business/product strategy and high-level roadmap and align analysis efforts to enable them with data insights and help achieve their strategic goals.
Strong audience focused presentation and storytelling skills focused on key takeaways in a crisp and concise manner.
Define, implement, and train statistical, machine learning, and deep learning models.
Use software engineering best practices to publish model scores/insights/learnings at scale within the company.
Ability to define and spot macro and micro levels trends with statistical significance on a regular basis and understand key drivers driving those trends.
Active role in hiring, growing, and mentoring the data scientist team in Austin.
Examples of desirable skills, knowledge and experience

M.S or Ph.D in Computer Science, Statistics, Mathematics, or other quantitative field.
Strong experience in scientific computing using Python, R, or Scala.
Experience with Spark, SQL, Tableau, Google Analytics, Hive and BigQuery (or any other Big data/Cloud equivalent) etc.
Experience working with and processing structured, unstructured, and semi-structured data.
Work closely with data engineering team to ensure robust data pipelines and model deployment.
Proven track record of applying data insights and machine learning in order to address business needs and drive revenue.
5+ years of data scientist experience with proven industry experience in a large scale environment (PBs scale, globally distributed teams).
2+ years experience with a fast-growing SaaS business based company is preferred.
Strong communication and presentation skills catered to different audience within the company.
Capable of working closely with business, engineering, and product teams to ensure data initiatives are aligned with business needs.
Experience in hiring data scientists and establishing team best practices is preferred.
What Makes Cloudflare Special?

We're not just a highly ambitious, large-scale technology company. We're a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.

Project Galileo ( https://blog.cloudflare.com/protecting-free-expression-online/ ): We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare's enterprise customers--at no cost.

Project Athenian ( https://www.cloudflare.com/athenian/ ): We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.

Path Forward Partnership ( https://blog.cloudflare.com/tag/path-forward/ ): Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.

1.1.1.1 ( https://1.1.1.1/ ): We released1.1.1.1 ( https://1.1.1.1/ ) to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here's the deal - we don't store client IP addresses never, ever. We will continue to abide by ourprivacy policy ( https://developers.cloudflare.com/1.1.1.1/commitment-to-privacy/privacy-policy/privacy-policy/ ) and ensure that no user data is sold to advertisers or used to target consumers.

Sound like something you'd like to be a part of? We'd love to hear from you!

Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.

Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94115."
Data Engineer (ATX),"Austin, TX",Ethos Life,,Organic,"About Ethos

Ethos is a new kind of life insurance built for people who don't have time for fine print, extra doctor's appointments or hidden fees. We have transformed a 15 week process of paper applications and medical exams, into just the click of a button - by quantifying the user's health risk using predictive models.

Our investors include Sequoia Capital, Accel Partners, Google Ventures, Jay-Z, Kevin Durant, and Robert Downey Jr. We are listed as CNBC's 100 startups to look out for ( https://www.cnbc.com/2018/10/09/cnbc-unveils-its-list-of-100-promising-startups-to-watch-in-2018.html ), as well as featured on Forbes for being one of Sequoia Capital's key investments. ( https://www.forbes.com/sites/peterhigh/2019/02/18/sequoia-partner-roelof-botha-describes-his-investment-philosophy/#3c5a54d65c4e ) We are growing quickly and looking for passionate people to protect the next million families.

Ethos is an extremely data driven company. We take every decision backed by data. Making data and insights available to everyone in the company is the mission of data engineering team. You will work with some of the brightest people helping drive infrastructure and insights to disrupt one of the oldest and largest industries in the country.

Duties and Responsibilities:
Build realtime data pipelines to ingest structured and unstructured data into data warehouse
Build ETL pipelines using Airflow to drive analytics, reporting and machine learning
Build and maintain data governance, classification and dictionary
Constantly improve A/B test framework and reporting
Support leadership and every single team with research on key business initiatives and challenges
Qualifications and Skills:
2+ years of solid software engineering experience
2+ years of experience with ETL and Data Pipelines
2+ years of experience with Airflow, Hive, Presto etc
2+ years of experience with Python
Comfortable with navigating complex topics and using data to make decisions
Excellent communication, presentation, and interpersonal skills
Everyone is welcome at Ethos. We are an equal opportunity employer who values diversity and inclusion and look for applicants who understand, embrace and thrive in a multicultural world. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Pursuant to the SF Fair Chance Ordinance, we will consider employment for qualified applicants with arrests and conviction records."
Senior Data Engineer,"Austin, TX 78704 (South Lamar-South Congress area)",Vida Clinic,,Organic,"Vida Clinic was awarded a Top Workplaces 2019 honor by The Austin American-Statesman!
You can use your tech skills to support a world-class team of mental health therapists and researchers providing unique, effective services in Texas schools.
Psychology + Technology = Vida Clinic
We are a growing team and there are opportunities for advancement.
The Vida Clinic Story:
We are the largest provider of School Mental Health Clinics in Texas. In 2015 we started operating our first School Mental Health Clinic (SMHC) at a south Austin high school. Vida Clinic's unique SMHCs remove multiple barriers to mental health access, including cost and transportation, while also reducing the stigma of treatment. Our clients quickly experienced measurable improvements in well-being, behavior and academics. Interest in our evidence-based model and measurable outcomes has enabled us to grow rapidly. We now operate over 50 clinics across Texas.
The Vida Clinic Mission:
To operate a Vida Clinic in every school that wants one.
Job Summary:
The Senior Data Engineer will lead our data engineering projects and help us grow our data team. Main responsibilities include RDBMs and big data infrastructure support, input data analysis, database design, importing data, data quality improvement, data report generation, and process improvement. The Data Engineering team will work in collaboration with data analysts and scientists.
We are an agency that values each person and their individual strengths. We offer a supportive environment that encourages and promotes professional growth, drawing upon the unique skills of our employees to contribute to a culture of effective innovation. Since we all are passionate about our work, we have built a culture that enables and rewards efficient and effective processes while promoting a work-life balance. This includes work schedules and employee benefits that encourage personal self-care. This job is based in Austin, Texas.
Vida Clinic Perks:
Join one of Austin's Top Workplaces in 2019
Competitive salary
Comprehensive benefits including medical, dental, vision, and life insurance
Employee Assistance Program and life wellness services
Paid Time Off
Retirement benefits
Plus many more – We have a whole team dedicated to making Vida Clinic an awesome place to work!
What You'll Do:
Infrastructure Support
Manage our cloud-based DB systems including RDBMS and big data systems
Integrate Input Data
Analyze data formats from a variety of systems
Design databases to support reporting and analysis needs
Importing Data
Compiles, scrubs, wrangles, and loads data into databases from a variety of source formats.
Establishes and updates data quality processes
Data Structure Analysis
Conduct detailed analysis of data, including monitoring and ensuring data quality, to be used as input for performance dashboards and reports.
Update database design
Recommend and implement improvements to data quality associated with processes.
Coordinate with stakeholders to improve data quality.
Reporting
Prepare standard and ad-hoc reports, for internal and external audiences.
Ensures accuracy of data included in reports.
Assists in the development and implementation of effective analytic techniques and review methodologies for evaluating and monitoring activities and initiatives.
Coordination
Utilizes strong communication skills to work with team members and partners to improve data input processes.
Coordinates with subject matter experts to ensure accuracy of reports and data input.
Provides routine updates on the status of projects and initiatives.
Identifies and Implements Improvements
Provides suggestions that will improve the collection of data and align data infrastructure with business needs.
Implements ETL processes to reduce manual steps for data acquisition.
Works with operations to improve data collection methods
Required Competencies & Skills
Strong SQL
Understanding of database design and application.
Strong Experience in data preparation, scrubbing, and integration.
Data Wrangling tools.
Data Analysis
Data Pipeline creation
ETL Parameterization
Python or Java
Cloud Database management. Preferably with Google cloud.
Proficient in Google Suite, Microsoft Office Suite or related software
Debugging/Problem Solving
Creativity
Ethical conduct
Flexibility and adaptability
Leadership
Credibility
Effective decision making (whether independently or in collaboration with Vida Clinic team members)
Thoroughness and accuracy
Collaboration skills
Communication proficiency
Effective time management
Organization
Friendly etiquette
Problem solving/analysis
Ability to work independently as well as in a collaborative environment
Preferred Skills
Google Cloud (GCP)
Postgressql
BigQuery
Trifacta Data Wrangling
Google Data Flow ETL
Visual Analysis and reporting (i.e. metabase or google data studio, apache zepplin)
R for statistical analysis
Implementation predictive models and machine-learning algorithms
Vida Clinic provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
yNVd7RpaXp"
Data Engineer,"Austin, TX",Wipro,,Organic,"Job Summary
Role: Data Engineer
Location: Beaverton,OR / Austin,TX / Sunnyvale,CA
Skills: Hadoop, Spark Kafka
Years of Experience: 8 - 12 years
Responsibilities and Duties
Design and implement distributed data processing pipelines using Spark, Hive, Python, and other tools and languages prevalent in the Hadoop ecosystem. Ability to design and implement end to end solution.
Experience publishing RESTful API’s to enable real-time data consumption using OpenAPI specifications
Experience with open source NOSQL technologies such as HBase, DynamoDB, Cassandra
Familiar with Distributed Stream Processing frameworks for Fast & Big Data like ApacheSpark, Flink, Kafka stream
Build utilities, user defined functions, and frameworks to better enable data flow patterns.
Work with architecture/engineering leads and other teams to ensure quality solutions are implements, and engineering best practices are defined and adhered to.
Experience in Business Rule management systems like Drools
DAAI_WIP
Job Type: Full-time
Experience:
HBase, DynamoDB, Cassandra: 1 year (Preferred)
Overall: 8 years (Required)
Spark, Hive, Python: 2 years (Preferred)
Location:
Austin, TX (Preferred)
Work authorization:
United States (Required)"
"Sr. Manager, Data Science","Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
You understand that the best managers serve their teams by removing roadblocks and giving individual contributors autonomy and ownership. You have high standards and will take pride in Indeed and push teammates to be better. You have delivered challenging technical solutions at scale. You have led Data Science or Engineering teams, and earned the respect of talented practitioners. You are equally happy talking about deep learning and statistical inference, as you are brainstorming about practical experimental design and technology career development. You love being in the mix technically while providing leadership to your teams.

Requirements
Significant prior success as a Data, Product, or Decision Scientist working on challenging problems at scale
Master’s or PhD., with advanced coursework in statistics, machine learning, programming, or related skills
5+ years of industry experience, with expertise in statistical modeling and/ or machine learning
The ability to guide a team to achieve important goals together
Expertise in machine learning and statistical modeling
Strong ability to code in Python
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring
Strong desire to solve tough problems with scientific rigor at scale
An understanding of the value derived from getting results early and iterating
Ability to write and present results to both technical and non-technical audiences
Strong ability to coach Data Scientists, helping them improve their skills and grow their careers
Passion to answer Product/Engineering questions with data
We get excited about candidates who can:
Program using R, Python, Java, or C++
Perform big data modeling work: Hadoop, Pig, Scala, Spark
Fish for data: SQL, Pandas, MongoDB
Deploy Data Science solutions: Java, Python, C++
Can communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Data Scientist,"Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

The base salary range below represents the low and high end of the Indeed salary range for this position. Actual salaries will vary and may be above or below the range based on various factors including but not limited to location, experience, and performance. The range listed is just one component of Indeed's total compensation package for employees. Other rewards may include quarterly bonuses, Long Term Incentive Plan units, an open Paid Time Off policy, and many region-specific benefits.

Austin Base Salary Range: 106,000 - 128,000 USD per year

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
Requirements

BS in Computer Science, Statistics, Mathematics or a closely related quantitative field
2 years of professional industry experience in Data Science, Business Analytics, or Data Analysis
Expertise in machine learning and statistical modeling
Passion to answer Product/Engineering questions with data
Strong ability to code in Python
We get excited about candidates who:
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring of data science products
Are proficient in small data modeling work: Python, R, Julia, Octave
Are proficient in big data modeling work: Hadoop, Pig, Scala, Spark
Can fish for data: SQL, Pandas, MongoDB
Deploy data science solutions: Java, Python, C++
Communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Data Engineer,"Austin, TX","Aunt Bertha, a Public Benefit Corp.",,Organic,"Our Mission: To connect all people in need and the programs that serve them (with dignity and ease).
Aunt Bertha picks up where Uncle Sam leaves off by making it easy to find and apply for government and charitable social service programs. By organizing the world's human service program information, we make it easy for people in need and the people who help them to find help in seconds on www.auntbertha.com.
We are looking for people who are driven to make the world a drastically better place and want to join our small group of thoughtful, committed citizens because they believe, as Margaret Mead said, ""Never doubt that a small group of thoughtful, committed citizens can change the world; indeed, it's the only thing that ever has.""
Please note: If our mission doesn't strike a chord with you that is OK. But please consider not applying. We are seeking people who come on fire after learning about what we do.
What We Need Your Help Doing: The Data Engineer is essential to helping Aunt Bertha design, build and maintain a scalable data platform. This role is key in automating data processes to enable focusing on business value while eliminating toil; taking a lead role in schema design, indexing, data transformation, custom SQL development and other data-centric development tasks; working with engineering and infrastructure stakeholders to design and improve our database architecture; and working with our data architect to advocate for and introduce new technologies to solve data-related challenges and position us to make significant advances in new areas of data strategy.
Key Responsibilities:
Manage and optimize existing MySQL databases (schemas, indexing, security)
Design solutions to data-centric issues like performance, scalability and manageability
Use knowledge of various approaches to managing data (e.g. relational, document-based, columnar, etc.) to propose and design solutions that best fit the business needs
Write code for new system features, especially those related to data or reporting. There will be a heavy emphasis on implementing ETLs with proficiency in SQL and Python.
Work with the wider engineering team to validate and implement product-driven schema changes
Troubleshoot database issues and performance during development and testing, and create appropriate fixes
Follow established processes for documentation, testing and deployment of data-related features
Handle customer-reported data-related bugs and change requests
We are looking for someone who:
Is driven by the mission of helping others through building amazing software
Is competent with the languages and tools needed to develop database software
Keeps current with new data technologies and matches the right tool to the problem
Loves automating as much as possible
Communicates effectively in writing and speaking
Nice-to-have skills:
Experience with git
Familiarity with Pentaho or similar ETL tools
Experience in Google Cloud Platform or similar cloud-based infrastructure
Experience with Ansible or other infrastructure-as-code solutions
Apply Now! We are selecting from a broad field of candidates. If you are interested in learning more and think you have what it takes to win, please respond to this job posting with:
Your résumé
A short cover letter in which you tell us who you are, what you want to achieve in life and how this job will help you get there, and why Aunt Bertha should strongly consider a deeper conversation with you.
A cover letter is required! We get a lot of applicants, and only those who are truly engaged with our company mission will likely move forward. Additionally, please provide samples or links to any prior work that demonstrate your skill set, if available (e.g. a Github repo, portfolio page, etc.)
Physical Demands & Work Environment: The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Some travel may be required.
We are proud to be an Equal Opportunity Employer and value diversity on our team.
Job Type: Full-time
Experience:
data/ETL: 3 years (Required)
Location:
Austin, TX (Required)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Parental leave
Other
Visa Sponsorship Potentially Available:
No: Not providing sponsorship for this job"
"Sr. Manager, Data Science","Austin, TX 78731",Indeed,,Organic,"Our mission:
As the world’s number 1 job site, our mission is to help people get jobs. We need talented, passionate people working together to make this happen. We are looking to grow our teams with people who share our energy and enthusiasm for creating the best experience for job seekers.

The team:
We are a rapidly growing and highly capable engineering team building the most popular job site on the planet. Every month, over 250 million people count on us to help them find jobs, publish their resumes, process their job applications, and connect them to qualified candidates for their job openings. With engineering hubs in Seattle, San Francisco, Austin, Tokyo and Hyderabad, we are improving people's lives all around the world, one job at a time.

Your job:
As a Data Scientist at Indeed your role is to follow the data. Analyze, visualize, and model job search related data. You will build and implement machine learning models to make timely decisions. You will have access to unparalleled resources within Indeed to grow and develop both personally and professionally.

We are looking for a mixture between a statistician, scientist, machine learning expert and engineer: someone who has passion for building and improving Internet-scale products informed by data. The ideal candidate understands human behavior and knows what to look for in the data.

About you:
You understand that the best managers serve their teams by removing roadblocks and giving individual contributors autonomy and ownership. You have high standards and will take pride in Indeed and push teammates to be better. You have delivered challenging technical solutions at scale. You have led Data Science or Engineering teams, and earned the respect of talented practitioners. You are equally happy talking about deep learning and statistical inference, as you are brainstorming about practical experimental design and technology career development. You love being in the mix technically while providing leadership to your teams.

Requirements
Significant prior success as a Data, Product, or Decision Scientist working on challenging problems at scale
Master’s or PhD., with advanced coursework in statistics, machine learning, programming, or related skills
5+ years of industry experience, with expertise in statistical modeling and/ or machine learning
The ability to guide a team to achieve important goals together
Expertise in machine learning and statistical modeling
Strong ability to code in Python
Have full stack experience in data collection, aggregation, analysis, visualization, productionization, and monitoring
Strong desire to solve tough problems with scientific rigor at scale
An understanding of the value derived from getting results early and iterating
Ability to write and present results to both technical and non-technical audiences
Strong ability to coach Data Scientists, helping them improve their skills and grow their careers
Passion to answer Product/Engineering questions with data
We get excited about candidates who can:
Program using R, Python, Java, or C++
Perform big data modeling work: Hadoop, Pig, Scala, Spark
Fish for data: SQL, Pandas, MongoDB
Deploy Data Science solutions: Java, Python, C++
Can communicate concisely and persuasively with engineers and product managers
Indeed provides a variety of benefits that help us focus on our mission of helping people get jobs.

View our bounty of perks: [1] http://indeedhi.re/IndeedBenefits

View Indeed's Applicant Privacy Terms: [2] https://www.indeed.com/legal/applicant-privacy"
Machine Learning Ops Engineer,"Austin, TX 78702 (Govalle area)",Pensa Systems,,Organic,"Job Description
Pensa leverages a variety of Machine Learning (ML) models to recognize Consumer Packaged Goods (CPGs) from videos acquired in live retailer locations. Retail is a naturally fast-paced environment with an ever growing and changing catalogue of CPGs. To ensure we maintain very high recognition accuracy in this dynamic environment, we continuously train, evaluation, and deploy new ML models.
This requires that we have a strong focus on the tooling and process for curating our training data sets and managing both the model and data lifecycles. We are looking to expand our ML team to support this strong focus on managing our data and managing the models we run in our production servers. The ML Ops Engineers work closely with the rest of the ML team to build tooling and process for understanding how the quality of our datasets impact our models, and ultimately how this impacts our overall system accuracy. Our ML Ops Engineers also work closely with our data team to ensure that we are building a strong feedback loop between human-curated datasets and machine trained models. This involves making good decisions about how we leverage our subject matter experts that label training data, and building the right feedback loops to allow our trained models to assist in the dataset management process.
Our ML Ops Engineers are responsible for:
Training, testing, and deploying new models into production and managing the full lifecycle of our production models.
Working with our Data Team to ensure that our annotation specialists have the tools and information to make good decisions about the labeled content they manage to ensure the overall quality of our training datasets.
Managing the process of ingesting new products into our dataset.
Evaluating the performance of our production models to identify when changes need to be made to our training data so that our recognition accuracy remains high.
Working with the ML, Software, and Product Management teams to identify requirements for improving our labeling, evaluation, and deployment tools and processes. The ideal candidate will be able to own some of the coding work for these tools.
Supporting our products and customers in a production environment.
Actively supporting our continuous journey of applying “just enough” process so that we can do our best work every day. Strong opinions are encouraged.
Requirements
2 or more years training and managing ML models using real-world data, ideally in a commercial environment with experience supporting a shipping product.
A strong understanding of data ingest and annotation lifecycles, and ideally and understanding of the services offered by the ecosystem of annotation vendors.
Hands-on experience with one of the major ML frameworks such as Tensorflow or PyTorch.
Hands-on experience working in a Unix/Linux environment.
Familiarity with the major ML-as-a-Service offerings such as AWS SageMaker, Google MLEngine, or Azure Machine Learning.
2 or more years of recent experience with Python.
Direct experience with and RDBMS such as PostgreSQL or MySQL.
Bachelor's degree in any technical field. An advanced degree is a plus.
About Pensa Systems
Pensa is a local Austin technology company and a leading innovator in autonomous perception systems for global retail inventory visibility. Our system uses breakthrough technology including artificial intelligence, autonomous drones and computer vision to understand what is on store shelves. We have snacks in the kitchen, beer in the fridge and flexible work hours. Although we work hard, we don’t get too wrapped up with protocol or bureaucracy. We appreciate the diversity of all stripes and are an equal opportunity employer. We are building really cool things that are disrupting multi-trillion-dollar global industries. If you enjoy working with cutting-edge technology and operating in a fast-paced, high-impact environment, then Pensa is the place for you. To learn more about us, please visit www.pensasystems.com and stay connected via Twitter and LinkedIn.
Job Type: Full-time
Experience:
Dev Ops: 3 years (Required)
Machine Learning: 1 year (Required)
Education:
Bachelor's (Required)"
Data Engineer,"Austin, TX 78735 (West Oak Hill area)","Buzz Points, Inc.",,Organic,"Buzz Points® is looking for a Data Engineer with a track record of playing an integral role in handling the design and construction of scalable management systems. The Data Engineer will join our Engineering team and report directly to the Director of Engineering.
What is Buzz Points?
Buzz Points® is revolutionizing the rewards industry for community banks and credit unions. As consumers grow weary of tired “points programs” with catalogs of undesirable merchandise for rewards, Buzz Points is leading the way for community financial institutions to differentiate and compete with the mega-banks and their eye-catching incentives.
The Buzz Points next-generation rewards platform offers the most advanced customer engagement and loyalty program in the industry. Community banks and credit unions utilize the innovative platform to offer exciting rewards for profitable behaviors on credit cards, debit cards and account-based behavioral activities, all while improving customer engagement and driving revenue.
Our holistic solution uses incentives to engage customers, support communities and “level the playing field” between community banks and credit unions and their mega-bank competition. It generates real revenue with a powerful combination of data-driven insights and unparalleled user experience to deliver undeniable bottom line results.
Buzz Points is a fast-growing company with over 50 financial institution customers in 28 states today. Our investors include Lead Edge Capital, KEC Ventures, Greycroft Partners, Wild Basin Investments, Daylight Partners, Metamorphic Partners, Discover Financial Services/PULSE and more.
What you’ll do:
It’s an exciting time at Buzz Points. Our platform has evolved around cloud centric technologies and we need capable engineers who understand the value of data. The role of a data systems and reporting analyst is a supporting one, but it is also an extremely vital one.
As a data engineer, you’ll be handling the design and construction of scalable management systems, ensure that all data systems meet company and compliance standards, as well as research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.
In order to be stand out as a candidate, you should express humility and patience. Data engineering is about building the underlying infrastructure, and so being able to pass the limelight to someone else is imperative. Furthermore, being able to listen to your colleagues is essential. Essential duties will include:
· Design, construct, install, test and maintain data management systems in AWS
· Build high-performance algorithms, predictive models, and prototypes.
· Ensure that all systems meet the business/company requirements as well as industry practices.
· Defines and develops standard reports for key data metrics.
· Develops custom and ad-hoc reports based on requirements provided by departments and customers.
· Integrate up-and-coming data management and software engineering technologies into existing data structures.
· Develop set processes for data mining, data modeling, and data production.
· Create custom software components and analytics applications.
· Research new uses for existing data.
· Employ an array of technological languages and tools to connect systems together.
· Collaborate with members of your team (eg, data architects, the IT team, data scientists) on the project’s goals.
· Install/update disaster recovery procedures.
· Recommend different ways to constantly improve data reliability and quality.
· Special projects and other duties will be assigned as needed.
· Represent the Buzz Points brand and mission with honesty, integrity, and professionalism.
Key Personality Traits:
Fit with our culture and natural leadership is important to the success of this role.
You must have the high energy, tenacity, and positivity. You must be high integrity, laser focused, and have a “need to succeed” at whatever you do.
Exercise a commanding and inspiring team collaboration style;
Constantly elevate and improve methods and be a natural analytical and diagnostic problem solver;
Ability to manage multiple initiatives while working independently.
What’s required:
Bachelor’s degree in computer science, software/computer engineering, applied mathematics, or physics statistics and 3 years of applicable work experience.
An understanding of AWS technologies such as S3, SQS, Lambda, AWS Glue, Athena, RDS DMS, DynamoDB, and Quick Sight are essential.
Proficiency in Python and bash or equivalent programming languages. Node.js is a plus.
It’s a bonus if you understand Kinesis or have setup event streaming for data pipelines.
An understanding of PostgreSQL or equivalent relational databases.
Experience in a related field with real-world skills and testimonials from former employees.
Possible work experience and proof of technical expertise.
Intellectual curiosity to find new and unusual ways of how to solve data management issues.
Ability to approach data organization challenges while keeping an eye on what’s important.
Self-Starter/Motivator who works well with others.
Customer-centric approach to work.
Experience working with community banks and credit unions is a plus.
Experience in similar roles with a fast-growing small business marketing or rewards program a plus.
Thrives in a high-tech, fast-paced, team-oriented environment.
Enthusiasm, positive attitude, self-motivation, and strong work ethic.
Organizational skills and attention to detail, as well as experience in change management and project management experience, are crucial.
Data Engineering FAQ:
What is included in the daily work of a data engineer?
A day on the job in data engineering consists of handling data within the organization, data transformation, and maintaining systems. Data query might also crop up quite a bit, as you’ll be asked by colleagues and customers to create reports.
Which technical languages should I learn to increase my chances of getting a job as a data engineer?
You should be well-versed in statistics, machine learning techniques, mathematics, and SQL databases. Python is also the most widely used programming language across the board when it comes to data engineering and we are migrating most of our legacy scripts to this language. Furthermore, a problem-solving, analytical knowledge of databases will also be a great asset.
What problems might data engineer run into?
Data engineering is probably the most research-extensive role in the organization, and so these roles come across a lot of problems. Some of these problems include the consideration of whether or not cloud storage will scale and knowing how long it will take to make it possible, as well as understanding why an import job failed for one of our internal or external stakeholders. Data engineering is part trial and error, and it is your job to diagnose and fix any failures that might occur.
Job Type: Full-time
Experience:
Data: 3 years (Preferred)
Work Location:
One location
Benefits:
Health insurance
Dental insurance
Vision insurance
Retirement plan
Paid time off
Flexible schedule
Parental leave"
Data Engineer,"Austin, TX",Wipro,,Organic,"Job Summary
Role: Data Engineer
Location: Beaverton,OR / Austin,TX / Sunnyvale,CA
Skills: Hadoop, Spark Kafka
Years of Experience: 8 - 12 years
Responsibilities and Duties
Design and implement distributed data processing pipelines using Spark, Hive, Python, and other tools and languages prevalent in the Hadoop ecosystem. Ability to design and implement end to end solution.
Experience publishing RESTful API’s to enable real-time data consumption using OpenAPI specifications
Experience with open source NOSQL technologies such as HBase, DynamoDB, Cassandra
Familiar with Distributed Stream Processing frameworks for Fast & Big Data like ApacheSpark, Flink, Kafka stream
Build utilities, user defined functions, and frameworks to better enable data flow patterns.
Work with architecture/engineering leads and other teams to ensure quality solutions are implements, and engineering best practices are defined and adhered to.
Experience in Business Rule management systems like Drools
DAAI_WIP
Job Type: Full-time
Experience:
HBase, DynamoDB, Cassandra: 1 year (Preferred)
Overall: 8 years (Required)
Spark, Hive, Python: 2 years (Preferred)
Location:
Austin, TX (Preferred)
Work authorization:
United States (Required)"
CRM and Data Engineer (Zoho One),"Austin, TX (South Lamar area)",Houndstooth Capital Real Estate,,Organic,"Houndstooth Capital Real Estate is a boutique real estate investment and development company in Austin, TX specializing in residential and multifamily assets. Houndstooth uses direct market intelligence to find real estate assets with value-add potential.
We are looking for a CRM expert to join our team. This is a high impact role, as our business relies on the efficient flow of information through our CRM. You will be responsible for the design, development, testing, and support of our customer relationship management ecosystem (Zoho One). You will lead and be responsible for designing and implementing our business processes to run on the Zoho One CRM platform.
This is a unique opportunity to collaborate with the founder and VP of Sales and dive into all parts of the process and learn the business by experiencing it first-hand. If you’re searching for a long-term partnership and a quick growth trajectory, this is the place for you.
As a Houndstooth team member, you bring a growth mindset, desire to learn new technologies/processes, strong communication skills and are a positive team player.
Every day will be different, but a majority of the time you will:
Own Zoho One’s full life cycle and it’s applications, including scripts, development roadmap, execution and maintenance
Drive strategic business results through building custom tools and scripts to automate manual business processes
Implement and customize business applications on Zoho One including CRM, Analytics, Motivator, Creator, Flow, Forms, Analytics, and other as needed
Migrate data from different systems into Zoho One from other platforms including third-party APIs such as the MLS
Create innovative, state-of-the-art applications and collaborate with the Sales team to gather requirements and develop software solutions
Develop and prioritize a feature development roadmap including new functionality, such as layouts, custom objects, and fields, reports and dashboards
Ensure HTML, CSS, and shared JavaScript is valid and consistent across applications
Utilize backend data services and contribute to increasing existing data services API
Optimize and improve the existing CRM system and work processes to scale efficiently
Document all components of the development process clearly
Keep abreast of new trends and best practices in web development
Produce efficient, clean, and well-commented code
Analyze, design, develop, test, and implement applications
Who you are:
Energetic self-starter, with a strong work ethic and sense of urgency who thrives in a fast-paced environment
Extreme owner over your work, solving problems proactively
Entrepreneurially spirited with a desire to work independently and drive your professional growth
Excellent communicator who values honesty and integrity
Well organized, detail-oriented with the capacity to multitask successfully
What you bring:
1 -2 years experience with a CRM product (Zoho CRM strongly preferred)
Ability to use one or more development language (PHP, Python, HTML, Java, MySQL, SQL Server, Linux, .NET, strong OOP concepts and/or C#)
Strong communication skills and a collaborative work style
Solutions-orientation with an eye for detail and identifying problems and roadblocks
Experience with IT troubleshooting principles and techniques
Understanding of and ability to implement application APIs
Bonus:
Experience with Zoho One including CRM, Analytics, Motivator, Creator, Flow, Forms, Analytics
Associates degree or higher in Computer Science, Information Systems, or Computer Engineering
Job Type: Full-time
Salary: $55,000.00 to $60,000.00 /year
Work Location:
One location
Benefits:
Paid time off
This Job Is:
A job for which military experienced candidates are encouraged to apply
Schedule::
Monday to Friday"
"Lead, People Analytics-Data Science","Austin, TX",Deloitte,,Organic,"Lead, People Analytics/Data Science
Works closely with other People Analytics team members to support defined projects that enhance the firm’s performance, productivity, and profitability through its people by conceptualizing analytical projects, mining, collecting and analyzing data, and providing actionable recommendations to guide the firm’s talent strategy across a wide variety of Talent topics including acquisition & mobility, leader/manager development, engagement, inclusiveness, individual/team performance, development, and exit. Partners with functional, geographic, and/or service lines to support the business and firm strategy.
Work you’ll do
Assists in the conceptualization of analytical projects to ensure research is rigorous and results provide actionable and comprehensive insights.
Develop statistical and ML models across a broad spectrum of topics, including both causal inference and predictive models.
Keeps up-to-date and introduces latest trends from technology and data science research (e.g., natural language processing, deep learning, reinforcement learning, etc.)
Design rigorous model validation studies and best practices
Locates and extract data from new data sources, finds new uses for existing data sources, structures and drives new data collection efforts, and provides recommendations on scaling new methods more broadly.
Integrates multiple systems and data sets to build large and complex data sets and make them usable (e.g., transforming and cleaning data, working incomplete data sources, implementing and validating quality procedures).
Conducts scalable data research and off and ultimately on the cloud.
Implements automated processes for efficiently producing scale models.
Liaises and collaborates with other COEs, Business Advisor organizations and Core Talent Services on the whole analytics lifecycle (conceptualization, data collection, analysis, and recommendations) or when subject matter expertise is required
Develops compelling, logically structured presentations (including story-telling of research/analytics findings) that will be shared at the Talent and business leadership level
Develops and maintains accurate and up-to-date project plans and status reports for all incoming and active projects.
The team
The People Analytics COE is responsible for:
Development and execution of the talent analytics and data strategy and roadmap
Development of strong partnerships within the business and Talent (Center Of Excellence, Core Talent Services, Business Advisors), to provide leadership, best practices and insight for how analytics can drive more meaningful decisions
Governance, execution, and coordination of data-driven strategic projects and analyses for Talent

Qualifications
Undergraduate degree (4 year) in Computer Science, Statistics, Applied Math or related field
2-3 years of applied experience in analytics and data mining
Master’s degree in Computer Science, Statistics, Applied Math or related field
1 year of applied experience in analytics and data mining
Have knowledge about the professional services industry; Deloitte experience preferred
Demonstrated accomplishments in the following areas:
Use a broad range of analytical skills to discover, mine, and analyze data to precisely reflect the organization’s or client’s needs and improving deliverable quality through verification and validation of results
Ability to work independently and manage multiple task assignments
Skilled at communicating with cross-functional team regarding deliverables, schedules, and issues
Creative problem-solving skills related to team, project, and cross-functional issues
Ability to maneuver in a matrix environment, leverage indirect reporting resources, and work well in ambiguous situations
Demonstrated capabilities in:
Data mining and statistical analysis that spans a range of disciplines.
Ability to understand various data structures and common methods in data transformation
Ability to use programming languages such as Java, Python, R and SQL
Working knowledge of statistics, programming and predictive modeling.
Possesses strong exploratory analysis skills
Familiarity with a range of disciplines such as: Natural language processing, machine learning, conceptual modelling, algorithms, statistical analysis, predictive modeling and hypothesis testing
Communication (excellent written/verbal communication, listening, and facilitation skills.)
Consulting skills (client service orientation, conflict resolution, analysis/synthesis of information, negotiation, etc.)
Professional judgment (including practical approach, appropriate risk taking, political savvy, and ethical judgment)
Ability to work in a remote environment, conscientious of key deadline deliverables, and ability to understand clients’ needs from ambiguous requirements
How you’ll grow
At Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to help sharpen skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.

Benefits
At Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.
Deloitte’s culture
Our positive and supportive culture encourages our people to do their best work every day. We celebrate individuals by recognizing their uniqueness and offering them the flexibility to make daily choices that can help them to be healthy, centered, confident, and aware. We offer well-being programs and are continuously looking for new ways to maintain a culture where our people excel and lead healthy, happy lives. Learn more about Life at Deloitte.

Corporate citizenship
Deloitte is led by a purpose: to make an impact that matters. This purpose defines who we are and extends to relationships with our clients, our people and our communities. We believe that business has the power to inspire and transform. We focus on education, giving, skill-based volunteerism, and leadership to help drive positive social impact in our communities. Learn more about Deloitte’s impact on the world.

Recruiter tips
We want job seekers exploring opportunities at Deloitte to feel prepared and confident. To help you with your interview, we suggest that you do your research: know some background about the organization and the business area you’re applying to. Check out recruiting tips from Deloitte professionals."
Data Science Lead,"Cedar Park, TX",Tekdoors Inc,,Organic,"Job Description:
Overall12+ years of experience and 8+ years of experience working as a Data Scientist
Experience/knowledge in statistics and data mining techniques, including, random forest, GLM/regression, social network analysis, text mining, etc.
Good working knowledge of cloud technologies (Azure and AWS preferred)
Experience with major big data technologies including Hadoop,S3, Spark, Redshift, etc.
Knowledge/experience on/with statistical programming languages, including R, Python to process data and gain insights from it
Experience using and developing data architectures
Knowledge of Machine Learning techniques, including decision tree learning, clustering, artificial neural networks, etc., and their pros and cons
Knowledge and application experience in advanced statistical techniques and concepts, including, regression, distribution properties, statistical testing, etc.
Multilingual coding knowledge/experience: Java, JavaScript, C, C++, etc.
Experience/knowledge in distributed data and computing tools, including, MapReduce, MySQL, Hadoop, Spark, Hive, etc.
Ability to use data visualization tools to showcase data for stakeholders like PowerBI, Tableau"
"Manager, Data Science","Austin, TX",Apple,,Organic,"Summary
Posted: Sep 11, 2019
Weekly Hours: 40
Role Number:200100421
Apple's Strategic Data Solutions (SDS) team is looking for a talented manager who is passionate about leading a team of data scientists that craft, implement, and operate analytical solutions that have direct and measurable impact to Apple and its customers. You will build and lead a team of SDS data scientists, who employ predictive modeling and statistical analysis techniques to build end-to-end solutions for improving security, fraud prevention, and operational efficiency across the company, from manufacturing to fulfillment to apps and services. Apple's dedication to customer privacy, the adversarial nature of fraud, and the enormous scale of the business present exciting challenges to traditional machine learning and data science techniques. On this team, you will push the limits of existing data science methods while delivering tangible business value.
Key Qualifications
Practical experience with and theoretical understanding of algorithms for classification, regression, clustering, and anomaly detection
Familiarity with database modeling and data warehousing principles and SQL.
Familiarity with Big Data tools like Spark, Hive etc.
Strong programming skills in Java, Python, or similar language
Ability to comprehend and debug complex systems integrations spanning toolchains and teams
Ability to extract meaningful business insights from data and identify the stories behind the patterns
Creativity to engineer novel features and signals, and to push beyond current tools and approaches
2+ years experience in hiring & leading team of data scientists.
Ability to coach data scientists and a drive to invest in team’s success.
Excellent presentation skills, distilling complex analysis and concepts into concise business-focused takeaways
Description
Engage with business teams to find opportunities, understand requirements, and translate those requirements into technical solutions • Design data science approach, applying tried-and-true techniques or developing custom algorithms as needed by the business problem • Collaborate with data engineers and platform architects to implement robust production real-time and batch decisioning solutions • Ensure operational and business metric health by monitoring production decision points • Investigate adversarial trends, identify behavior patterns, and respond with agile logic changes • Communicate results of analyses to business partners and executives • Research new technologies and methods across data science, data engineering, and data visualization to improve the technical capabilities of the team
Education & Experience
Ph.D. or Masters in a quantitative field, such as Computer Science, Applied Mathematics, or Statistics, or equivalent professional experience."
Data Scientist,"Austin, TX",Cerebri AI,,Organic,"Design, develop, test, advocate, evangelize and build data-driven products that help our customers improve business decisions. You will provide insight into analytic practices, design and lead iterative learning and development cycles.

Responsibilities
Understanding and worked with database systems.
Understanding and worked with machine learning algorithms.
Perform feature analysis.
Develop ontology for key market segments.
Develop outcome/event taxonomy for key business models.
Build utility code and handle miscellaneous support tasks.
Documenting software projects and maintaining project documentation.
Working in a team environment as well as working alone.
Qualifications
Experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning.
Python programming skills with two (2) years or more of Python experience.
Good verbal and written communication skills.
Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
Master's degree or six (6) years related work experience delivering quality code on time.
Tools we use...
Confluence
JIRA
Spark
Azure
Python
Keras
Scikit-learn
Bit bucket
Jupyter Notebook
Scala
MonetdB
OrientDB
Nice to haves...
Experience in some subset of the following: Java, R, Python, SQL, Scala, Spark.
Ph.D. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline.
Deep understanding of statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques, supervised learning, recommendation and optimization algorithms."
